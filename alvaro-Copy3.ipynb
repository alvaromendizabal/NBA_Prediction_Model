{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import requests\n",
    "import nba_api\n",
    "from nba_api.stats.endpoints import teamdashboardbygeneralsplits, leaguedashteamstats\n",
    "from nba_api.stats.endpoints import leaguegamelog, scoreboard, leaguestandings\n",
    "\n",
    "from datetime import date, timedelta\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# from sklearn import model_selection\n",
    "# from sklearn.utils import class_weight\n",
    "# from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile a dictionary of all 30 NBA teams and their Team ID\n",
    "teams = {\"Atlanta Hawks\": 1610612737,\n",
    "        \"Boston Celtics\": 1610612738,\n",
    "        \"Brooklyn Nets\": 1610612751,\n",
    "        \"Charlotte Bobcats\": 1610612766,\n",
    "        \"Charlotte Hornets\": 1610612766,\n",
    "        \"Chicago Bulls\": 1610612741,\n",
    "        \"Cleveland Cavaliers\": 1610612739,\n",
    "        \"Dallas Mavericks\": 1610612742,\n",
    "        \"Denver Nuggets\": 1610612743,\n",
    "        \"Detroit Pistons\": 1610612765,\n",
    "        \"Golden State Warriors\": 1610612744,\n",
    "        \"Houston Rockets\": 1610612745,\n",
    "        \"Indiana Pacers\": 1610612754,\n",
    "        \"LA Clippers\": 1610612746,\n",
    "        \"Los Angeles Clippers\": 1610612746,\n",
    "        \"Los Angeles Lakers\": 1610612747,\n",
    "        \"Memphis Grizzlies\": 1610612763,\n",
    "        \"Miami Heat\": 1610612748,\n",
    "        \"Milwaukee Bucks\": 1610612749,\n",
    "        \"Minnesota Timberwolves\": 1610612750,\n",
    "        \"New Jersey Nets\": 1610612751,\n",
    "        \"New Orleans Hornets\": 1610612740,\n",
    "        \"New Orleans Pelicans\": 1610612740,\n",
    "        \"New York Knicks\": 1610612752,\n",
    "        \"Oklahoma City Thunder\": 1610612760,\n",
    "        \"Orlando Magic\": 1610612753,\n",
    "        \"Philadelphia 76ers\": 1610612755,\n",
    "        \"Phoenix Suns\": 1610612756,\n",
    "        \"Portland Trail Blazers\": 1610612757,\n",
    "        \"Sacramento Kings\": 1610612758,\n",
    "        \"San Antonio Spurs\": 1610612759,\n",
    "        \"Toronto Raptors\": 1610612761,\n",
    "        \"Utah Jazz\": 1610612762,\n",
    "        \"Washington Wizards\": 1610612764,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Stats\n",
    "Stats like field goal percentage, rebounds, and turnovers are easily digested by NBA viewers. Some people don't like stats. They would rather apply the eye-test and see for themselves whether a team is any good. Others realize that stats can tell a story about the game but only if they know how to use them. Advanced stats play this role and help us dissect the drama unfolding on the court. Therefore, traditional and advanced stats will be cast in our models.\n",
    "\n",
    "#### True Shooting Percentage\n",
    "There are 3 ways that an NBA player can score: 3-pointers, 2-pointers and free throws. True shooting percentage ('TS_PCT') looks at all three. 3-pointers are a little tricky to factor into the equation. The max true shooting percentage  is 150% and can only be reached if a player hits every one of their shots and they're all from behind the arch. Because this stat accounts for all shots, it's easily the best measure of shooting ability. \n",
    "\n",
    "For example, if a player goes 1-for-1 and their only shot is from the hash-mark, the formula will read and simplify as follows (please just trust and accept that the .44 multiplier is the best way of estimating the total number of possessions a player is involved in):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{points} {2 *fga + .44 * fta}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{3}  {2 * 1 + .44 * 0} = \\frac{3}{2} = {1.5}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile a dictionary of stats and their source \n",
    "available_stats = {'W_PCT': 'Base',\n",
    "                   'FG_PCT': 'Base',\n",
    "                   'FG3_PCT': 'Base',\n",
    "                   'FT_PCT': 'Base',\n",
    "                   'REB': 'Base',\n",
    "                   'AST': 'Base',\n",
    "                   'TOV': 'Base',\n",
    "                   'STL': 'Base',\n",
    "                   'BLK': 'Base',\n",
    "                   'PLUS_MINUS': 'Base',\n",
    "                   'OFF_RATING': 'Advanced',\n",
    "                   'DEF_RATING': 'Advanced',\n",
    "                   'TS_PCT': 'Advanced'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Offensive and defensive rating\n",
    "Basketball stresses efficiency. Minimizing points allowed and maximizing points scored on each possession is more important than overall totals. Totals are shaped by variables like pace — or the number of possessions a team gets in a game — which differs depending on coaching (i.e. the Golden State Warriors averaged 3 fewer possessions per game than the Los Angeles Lakers last season).\n",
    "\n",
    "This is where tempo-free stats offensive and defensive rating come into play. Defensive rating shows how many points a player allows per 100 possessions. This statistic functions differently than a plus/minus system, where all points scored while a player is on the court count against them. Only the shots that are scored as a result of their defensive lapses are counted against them. \n",
    "\n",
    "Offensive rating is simpler to calculate. It's just the amount of points produced by a player per 100 possessions. Again, the reason offensive and defensive ratings are useful is because they're tempo-free stats. Offensive and defensive rating eliminate factors like pace of play and minutes played per game. Below is the formula for offensive rating:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\frac{100*pp} {fga + .44 * fta + to}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W_PCT': 0.646,\n",
       " 'FG_PCT': 0.469,\n",
       " 'FG3_PCT': 0.364,\n",
       " 'FT_PCT': 0.769,\n",
       " 'REB': 45.9,\n",
       " 'AST': 27.4,\n",
       " 'TOV': 15.0,\n",
       " 'STL': 8.9,\n",
       " 'BLK': 4.6,\n",
       " 'PLUS_MINUS': 5.6,\n",
       " 'OFF_RATING': 112.1,\n",
       " 'DEF_RATING': 106.6,\n",
       " 'TS_PCT': 0.582}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nba_api.stats.endpoints import teamdashboardbygeneralsplits, leaguedashteamstats\n",
    "\n",
    "\n",
    "def get_team_stats_dict(team, start_date, end_date, season='2021-22'):\n",
    "    \"\"\"\n",
    "    Returns the stats for the selected team in a dataframe, default year is 2021-22\n",
    "    :param start_data: Day of games scheduled in form 'mm/dd/yyyy'\n",
    "    :param end_data: Day of games scheduled in form 'mm/dd/yyyy'\n",
    "    :param season: Day of games scheduled in form 'yyyy-yy'\n",
    "    :return: A dictionary of game matchups {home_team:[away_team]}\n",
    "    \"\"\"\n",
    "\n",
    "    time.sleep(1)\n",
    "\n",
    "    \n",
    "    general_team_info = teamdashboardbygeneralsplits.TeamDashboardByGeneralSplits(team_id=teams[team],\n",
    "                                                                                  per_mode_detailed='Per100Possessions',\n",
    "                                                                                  season=season,\n",
    "                                                                                  date_from_nullable=start_date,\n",
    "                                                                                  date_to_nullable=end_date,\n",
    "                                                                                  timeout=120)\n",
    "    general_team_dict = general_team_info.get_normalized_dict()\n",
    "    general_team_dashboard = general_team_dict['OverallTeamDashboard'][0]\n",
    "\n",
    "\n",
    "    win_percentage = general_team_dashboard['W_PCT']\n",
    "    fg_percentage = general_team_dashboard['FG_PCT']\n",
    "    fg3_percentage = general_team_dashboard['FG3_PCT']\n",
    "    ft_percentage = general_team_dashboard['FT_PCT']\n",
    "    rebounds = general_team_dashboard['REB']\n",
    "    assists = general_team_dashboard['AST']\n",
    "    turnovers = general_team_dashboard['TOV']\n",
    "    steals = general_team_dashboard['STL']\n",
    "    blocks = general_team_dashboard['BLK']\n",
    "    plus_minus = general_team_dashboard['PLUS_MINUS']\n",
    "\n",
    "    advanced_team_info = teamdashboardbygeneralsplits.TeamDashboardByGeneralSplits(team_id=teams[team],\n",
    "                                                                                   measure_type_detailed_defense='Advanced',\n",
    "                                                                                   season=season,\n",
    "                                                                                   date_from_nullable=start_date,\n",
    "                                                                                   date_to_nullable=end_date,\n",
    "                                                                                   timeout=120)\n",
    "    advanced_team_dict = advanced_team_info.get_normalized_dict()\n",
    "    advanced_team_dashboard = advanced_team_dict['OverallTeamDashboard'][0]\n",
    "\n",
    "    offensive_rating = advanced_team_dashboard['OFF_RATING']\n",
    "    defensive_rating = advanced_team_dashboard['DEF_RATING']\n",
    "    true_shooting_percentage = advanced_team_dashboard['TS_PCT']\n",
    "\n",
    "    all_stats_dict = {\n",
    "        'W_PCT': win_percentage,\n",
    "        'FG_PCT': fg_percentage,\n",
    "        'FG3_PCT': fg3_percentage,\n",
    "        'FT_PCT': ft_percentage,\n",
    "        'REB': rebounds,\n",
    "        'AST': assists,\n",
    "        'TOV': turnovers,\n",
    "        'STL': steals,\n",
    "        'BLK': blocks,\n",
    "        'PLUS_MINUS': plus_minus,\n",
    "        'OFF_RATING': offensive_rating,\n",
    "        'DEF_RATING': defensive_rating,\n",
    "        'TS_PCT': true_shooting_percentage\n",
    "    }\n",
    "\n",
    "    return all_stats_dict\n",
    "\n",
    "\n",
    "get_team_stats_dict('Golden State Warriors', '10/19/2021', '04/10/2022', '2021-22')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nba_api.stats.endpoints import leaguegamelog, scoreboard, leaguestandings\n",
    "\n",
    "def get_match_results(date, season):\n",
    "    \"\"\"\n",
    "    Returns the matchup and result of the game\n",
    "\n",
    "    :param date: Day of games scheduled in form 'mm/dd/yyyy'\n",
    "    :param season: Season in form of 'yyyy-yy'\n",
    "    :return: [{Golden State Warriors: Boston Celtics}], ['W']\n",
    "    \"\"\"\n",
    "\n",
    "    game_log = leaguegamelog.LeagueGameLog(season=season, league_id='00', date_from_nullable=date,\n",
    "                                           date_to_nullable=date, season_type_all_star='Regular Season', timeout=120)\n",
    "    game_log_dict = game_log.get_normalized_dict()\n",
    "    list_of_teams = game_log_dict['LeagueGameLog']\n",
    "\n",
    "    daily_match = {}\n",
    "    win_loss = []\n",
    "    score = []\n",
    "    game_id = []\n",
    "\n",
    "    for i in range(0, len(list_of_teams), 2):\n",
    "\n",
    "        if '@' in list_of_teams[i]['MATCHUP']:\n",
    "\n",
    "            away_team = list_of_teams[i]['TEAM_NAME']\n",
    "            home_team = list_of_teams[i + 1]['TEAM_NAME']\n",
    "\n",
    "            win_loss.append(list_of_teams[i + 1]['WL'])\n",
    "\n",
    "            game_id.append(list_of_teams[i + 1]['GAME_ID'])\n",
    "\n",
    "            score.append(list_of_teams[i + 1]['PTS'])\n",
    "            score.append(list_of_teams[i]['PTS'])\n",
    "\n",
    "        else:\n",
    "            away_team = list_of_teams[i + 1]['TEAM_NAME']\n",
    "            home_team = list_of_teams[i]['TEAM_NAME']\n",
    "\n",
    "            win_loss.append(list_of_teams[i]['WL'])\n",
    "\n",
    "            game_id.append(list_of_teams[i]['GAME_ID'])\n",
    "\n",
    "            score.append(list_of_teams[i]['PTS'])\n",
    "            score.append(list_of_teams[i + 1]['PTS'])\n",
    "\n",
    "        daily_match.update({home_team: away_team})\n",
    "\n",
    "    match_results = [daily_match, win_loss, score, game_id]\n",
    "\n",
    "    return match_results\n",
    "\n",
    "\n",
    "def get_daily_matches(date):\n",
    "    \"\"\"\n",
    "    This method creates a dictionary of daily game matchups and their results.\n",
    "\n",
    "    :param date: Day of games scheduled in form 'mm/dd/yyyy'\n",
    "    :return: A dictionary of game matchups {home_team:away_team}\n",
    "    \"\"\"\n",
    "\n",
    "    daily_match = scoreboard.Scoreboard(league_id='00', game_date=date, timeout=120)\n",
    "    daily_match_dict = daily_match.get_normalized_dict()\n",
    "    games = daily_match_dict['GameHeader']\n",
    "\n",
    "    match = {}\n",
    "\n",
    "    for game in games:\n",
    "\n",
    "        home_team_id = game['HOME_TEAM_ID']\n",
    "\n",
    "        for team, team_id in teams.items():\n",
    "            if team_id == home_team_id:\n",
    "                home_team = team\n",
    "\n",
    "        away_team_id = game['VISITOR_TEAM_ID']\n",
    "\n",
    "        for team, team_id in teams.items():\n",
    "            if team_id == away_team_id:\n",
    "                away_team = team\n",
    "\n",
    "        match.update({home_team: away_team})\n",
    "\n",
    "    return match\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(f\"\"\"'get_daily_matches()' returns a dictionary of the games on a specified date\\n{get_daily_matches('12/25/22')}\\n\"\"\")\n",
    "    print(f\"\"\"'get_match_results()' returns the matchup plus the result\\n{get_match_results('10/19/2021', '2021-22')}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'get_daily_matches' returns a dictionary of the games on a specified date\n",
      "{'New York Knicks': 'Philadelphia 76ers', 'Dallas Mavericks': 'Los Angeles Lakers', 'Boston Celtics': 'Milwaukee Bucks', 'Golden State Warriors': 'Memphis Grizzlies', 'Denver Nuggets': 'Phoenix Suns'}\n",
      "\n",
      "'get_match_results' returns the matchup plus the result\n",
      "[{'Los Angeles Lakers': 'Golden State Warriors', 'Milwaukee Bucks': 'Brooklyn Nets'}, ['L', 'W'], [114, 121, 127, 104], ['0022100002', '0022100001']]\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datetime import date, timedelta\n",
    "import requests\n",
    "\n",
    "\n",
    "\n",
    "# [{'Sacramento Kings': 'Boston Celtics', 'Charlotte Hornets': 'Philadelphia 76ers'}, ['W', 'L']]\n",
    "def to_dataframe(daily_games, start_date, end_date, season): #, mean_dict, std_dict):\n",
    "    full_dataframe = []\n",
    "    game_number = 0  # counter to match with the correct game\n",
    "    daily_results = daily_games[1]  # win or loss for each game\n",
    "    score = daily_games[2]\n",
    "    game_id = daily_games[3]\n",
    "\n",
    "    for home_team, away_team in daily_games[0].items():  # loops through matchups\n",
    "        home_team_stats = get_team_stats_dict(home_team, start_date, end_date, season)\n",
    "        away_team_stats = get_team_stats_dict(away_team, start_date, end_date, season)\n",
    "\n",
    "        current_game = [home_team, away_team]\n",
    "        \n",
    "        current_game.append(game_id[game_number])\n",
    "\n",
    "        current_game.append(score.pop(0))\n",
    "\n",
    "        for stat, stat_type in available_stats.items():\n",
    "            current_game.append(home_team_stats[stat])\n",
    "        \n",
    "        current_game.append(score.pop(0))\n",
    "\n",
    "        for stat, stat_type in available_stats.items():\n",
    "            current_game.append(away_team_stats[stat])\n",
    "\n",
    "\n",
    "        #for stat, stat_type in available_stats.items():\n",
    "        #    z_score_diff = z_score_difference(home_team_stats[stat], away_team_stats[stat], mean_dict[stat], std_dict[stat])\n",
    "\n",
    "         #   current_game.append(z_score_diff)\n",
    "\n",
    "        if daily_results[game_number] == 'W':\n",
    "            result = 1\n",
    "        else:\n",
    "            result = 0\n",
    "\n",
    "        current_game.append(result)\n",
    "        game_number += 1\n",
    "\n",
    "        print(current_game)\n",
    "\n",
    "        full_dataframe.append(current_game)\n",
    "\n",
    "    return full_dataframe\n",
    "\n",
    "\n",
    "\n",
    "def date_range(start_date, end_date):\n",
    "    for n in range(int((end_date - start_date).days)):\n",
    "        yield start_date + timedelta(n)\n",
    "        \n",
    "\n",
    "def training_set(start_year, start_month, start_day, end_year, end_month, end_day, season, season_start):\n",
    "    start_date = date(start_year, start_month, start_day)\n",
    "    end_date = date(end_year, end_month, end_day)\n",
    "\n",
    "    total_games = []\n",
    "\n",
    "    for single_date in date_range(start_date, end_date):\n",
    "        current_date = single_date.strftime('%m/%d/%Y')\n",
    "        print(current_date)\n",
    "\n",
    "        previous_day = single_date - timedelta(days=1)\n",
    "        previous_day_formatted = previous_day.strftime('%m/%d/%Y')\n",
    "\n",
    "        #mean_std_dictionary = mean_std_dict(season_start, previous_day_formatted, season)\n",
    "        #mean_dict = mean_std_dictionary[0]\n",
    "        #std_dict = mean_std_dictionary[1]\n",
    "\n",
    "        current_day_games = get_match_results(current_date, season)\n",
    "        current_day_games_with_stats = to_dataframe(current_day_games, season_start, previous_day_formatted, season)\n",
    "\n",
    "        for game in current_day_games_with_stats:\n",
    "            game.append(current_date)\n",
    "            total_games.append(game)\n",
    "\n",
    "    print(total_games)\n",
    "    return total_games\n",
    "\n",
    "\n",
    "def make_dataframe(game_list):\n",
    "    games = pd.DataFrame(game_list,\n",
    "                         columns=['Home', 'Away', 'Game_ID', 'H_Score', 'H_W_PCT', 'H_FG_PCT', 'H_FG3_PCT', 'H_FT_PCT',\n",
    "                                  'H_REB', 'H_AST', 'H_TOV', 'H_STL',\n",
    "                                  'H_BLK', 'H_PLUS_MINUS', 'H_OFF_RATING', 'H_DEF_RATING', 'H_TS_PCT', 'A_Score',\n",
    "                                  'A_W_PCT', 'A_FG_PCT', 'A_FG3_PCT',\n",
    "                                  'A_FT_PCT', 'A_REB', 'A_AST', 'A_TOV', 'A_STL',\n",
    "                                  'A_BLK', 'A_PLUS_MINUS', 'A_OFF_RATING', 'A_DEF_RATING', 'A_TS_PCT', 'Result',\n",
    "                                  'Date'])\n",
    "\n",
    "    print(games)\n",
    "    return games\n",
    "\n",
    "\n",
    "def main():\n",
    "    attempts = 10\n",
    "\n",
    "    for i in range(attempts):\n",
    "        try:\n",
    "            all_games = training_set(start_year=2016, start_month=12, start_day=14, end_year=2017, end_month=1, end_day=4,\n",
    "                             season='2016-17', season_start='10/25/2016')\n",
    "            df = make_dataframe(all_games)\n",
    "\n",
    "            print(df)\n",
    "            df.to_csv(r'C:\\Users\\alvaro\\OneDrive\\Documents\\School\\Flatiron\\Projects\\NBA_Prediction_Model\\data\\nba_df_2016_v4.csv', index=False)\n",
    "        except requests.exceptions.ReadTimeout:\n",
    "            if i < attempts - 1:\n",
    "                continue\n",
    "            else:\n",
    "                raise\n",
    "        break\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seasons\n",
    "## 2016 - 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2016 = pd.read_csv('./data/nba_df_2016.csv')\n",
    "df_2016['Date'] = pd.to_datetime(df_2016['Date'])\n",
    "df_2016['Season'] = '2016-17'\n",
    "\n",
    "df_2016_2 = pd.read_csv('./data/nba_df_2016_v2.csv')\n",
    "df_2016_2['Date'] = pd.to_datetime(df_2016_2['Date'])\n",
    "df_2016_2['Season'] = '2016-17'\n",
    "\n",
    "df_2016_3 = pd.read_csv('./data/nba_df_2016_v3.csv')\n",
    "df_2016_3['Date'] = pd.to_datetime(df_2016_3['Date'])\n",
    "df_2016_3['Season'] = '2016-17'\n",
    "\n",
    "df_2016_4 = pd.read_csv('./data/nba_df_2016_v4.csv')\n",
    "df_2016_4['Date'] = pd.to_datetime(df_2016_4['Date'])\n",
    "df_2016_4['Season'] = '2016-17'\n",
    "\n",
    "df_2016_5 = pd.read_csv('./data/nba_df_2016_v5.csv')\n",
    "df_2016_5['Date'] = pd.to_datetime(df_2016_5['Date'])\n",
    "df_2016_5['Season'] = '2016-17'\n",
    "\n",
    "print(len(df_2016), len(df_2016_2), len(df_2016_3), len(df_2016_4), len(df_2016_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [df_2016, df_2016_2, df_2016_3, df_2016_4, df_2016_5]\n",
    "df_2016_final = pd.concat(frames)\n",
    "len(df_2016_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2017 - 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171 546 493\n"
     ]
    }
   ],
   "source": [
    "df_2017 = pd.read_csv('./data/nba_df_2017.csv')\n",
    "df_2017['Date'] = pd.to_datetime(df_2017['Date'])\n",
    "df_2017['Season'] = '2017-18'\n",
    "\n",
    "df_2017_2 = pd.read_csv('./data/nba_df_2017_v2.csv')\n",
    "df_2017_2['Date'] = pd.to_datetime(df_2017_2['Date'])\n",
    "df_2017_2['Season'] = '2017-18'\n",
    "\n",
    "df_2017_3 = pd.read_csv('./data/nba_df_2017_v3.csv')\n",
    "df_2017_3['Date'] = pd.to_datetime(df_2017_3['Date'])\n",
    "df_2017_3['Season'] = '2017-18'\n",
    "\n",
    "print(len(df_2017), len(df_2017_2), len(df_2017_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1210"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames = [df_2017, df_2017_2, df_2017_3]\n",
    "df_2017_final = pd.concat(frames)\n",
    "len(df_2017_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2018 - 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1203\n"
     ]
    }
   ],
   "source": [
    "df_2018 = pd.read_csv('./data/nba_df_2018.csv')\n",
    "df_2018['Date'] = pd.to_datetime(df_2018['Date'])\n",
    "df_2018['Season'] = '2018-19'\n",
    "\n",
    "print(len(df_2018))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2019 - 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "951 84\n"
     ]
    }
   ],
   "source": [
    "df_2019 = pd.read_csv('./data/nba_df_2019.csv')\n",
    "df_2019['Date'] = pd.to_datetime(df_2019['Date'])\n",
    "df_2019['Season'] = '2019-20'\n",
    "\n",
    "df_2019_2 = pd.read_csv('./data/nba_df_2019_2.csv')\n",
    "df_2019_2['Date'] = pd.to_datetime(df_2019_2['Date'])\n",
    "df_2019_2['Season'] = '2019-20'\n",
    "\n",
    "print(len(df_2019), len(df_2019_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1035"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames = [df_2019, df_2019_2]\n",
    "df_2019_final = pd.concat(frames)\n",
    "len(df_2019_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2020 - 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 582 469\n"
     ]
    }
   ],
   "source": [
    "df_2021 = pd.read_csv('./data/nba_df_2020_v0.csv')\n",
    "df_2021['Date'] = pd.to_datetime(df_2021['Date'])\n",
    "df_2021['Season'] = '2020-21'\n",
    "\n",
    "df_2021_2 = pd.read_csv('./data/nba_df_2020.csv')\n",
    "df_2021_2['Date'] = pd.to_datetime(df_2021_2['Date'])\n",
    "df_2021_2['Season'] = '2020-21'\n",
    "\n",
    "df_2021_3 = pd.read_csv('./data/nba_df_2020_v2.csv')\n",
    "df_2021_3['Date'] = pd.to_datetime(df_2021_3['Date'])\n",
    "df_2021_3['Season'] = '2020-21'\n",
    "\n",
    "print(len(df_2021), len(df_2021_2), len(df_2021_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1056"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames = [df_2021, df_2021_2, df_2021_3]\n",
    "df_2021_final = pd.concat(frames)\n",
    "len(df_2021_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2021 - 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61 159 784 199\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_2022 = pd.read_csv('./data/nba_game_2022.csv')\n",
    "df_2022['Date'] = pd.to_datetime(df_2022['Date'])\n",
    "df_2022['Season'] = '2021-22'\n",
    "\n",
    "df_2022_1 = pd.read_csv('./data/nba_game_2022_v1.csv')\n",
    "df_2022_1['Date'] = pd.to_datetime(df_2022_1['Date'])\n",
    "df_2022_1['Season'] = '2021-22'\n",
    "\n",
    "df_2022_2 = pd.read_csv('./data/nba_game_2022_v2.csv')\n",
    "df_2022_2['Date'] = pd.to_datetime(df_2022_2['Date'])\n",
    "df_2022_2['Season'] = '2021-22'\n",
    "\n",
    "df_2022_3 = pd.read_csv('./data/nba_game_2022_v3.csv')\n",
    "df_2022_3['Date'] = pd.to_datetime(df_2022_3['Date'])\n",
    "df_2022_3['Season'] = '2021-22'\n",
    "\n",
    "print(len(df_2022), len(df_2022_1), len(df_2022_2), len(df_2022_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of 2022 data: 1203\n",
      "\n"
     ]
    }
   ],
   "source": [
    "frames = [df_2022, df_2022_1, df_2022_2, df_2022_3]\n",
    "df_2022_final = pd.concat(frames)\n",
    "\n",
    "print(f\"Length of 2022 data: {len(df_2022_final)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Home</th>\n",
       "      <th>Away</th>\n",
       "      <th>Game_ID</th>\n",
       "      <th>H_Score</th>\n",
       "      <th>H_W_PCT</th>\n",
       "      <th>H_FG_PCT</th>\n",
       "      <th>H_FG3_PCT</th>\n",
       "      <th>H_FT_PCT</th>\n",
       "      <th>H_REB</th>\n",
       "      <th>H_AST</th>\n",
       "      <th>...</th>\n",
       "      <th>A_TOV</th>\n",
       "      <th>A_STL</th>\n",
       "      <th>A_BLK</th>\n",
       "      <th>A_PLUS_MINUS</th>\n",
       "      <th>A_OFF_RATING</th>\n",
       "      <th>A_DEF_RATING</th>\n",
       "      <th>A_TS_PCT</th>\n",
       "      <th>Result</th>\n",
       "      <th>Date</th>\n",
       "      <th>Season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Philadelphia 76ers</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>21700019</td>\n",
       "      <td>92</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.737</td>\n",
       "      <td>45.3</td>\n",
       "      <td>23.6</td>\n",
       "      <td>...</td>\n",
       "      <td>13.5</td>\n",
       "      <td>11.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-5.5</td>\n",
       "      <td>99.5</td>\n",
       "      <td>106.1</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-10-20</td>\n",
       "      <td>2017-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Phoenix Suns</td>\n",
       "      <td>Los Angeles Lakers</td>\n",
       "      <td>21700026</td>\n",
       "      <td>130</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.722</td>\n",
       "      <td>33.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>6.7</td>\n",
       "      <td>-15.2</td>\n",
       "      <td>87.6</td>\n",
       "      <td>101.9</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-10-20</td>\n",
       "      <td>2017-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brooklyn Nets</td>\n",
       "      <td>Orlando Magic</td>\n",
       "      <td>21700022</td>\n",
       "      <td>126</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.479</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.906</td>\n",
       "      <td>37.4</td>\n",
       "      <td>19.1</td>\n",
       "      <td>...</td>\n",
       "      <td>14.4</td>\n",
       "      <td>7.7</td>\n",
       "      <td>8.7</td>\n",
       "      <td>6.7</td>\n",
       "      <td>111.5</td>\n",
       "      <td>103.8</td>\n",
       "      <td>0.564</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-10-20</td>\n",
       "      <td>2017-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Milwaukee Bucks</td>\n",
       "      <td>Cleveland Cavaliers</td>\n",
       "      <td>21700021</td>\n",
       "      <td>97</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.833</td>\n",
       "      <td>45.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17.3</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>104.1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.543</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-10-20</td>\n",
       "      <td>2017-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Indiana Pacers</td>\n",
       "      <td>Portland Trail Blazers</td>\n",
       "      <td>21700018</td>\n",
       "      <td>96</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.781</td>\n",
       "      <td>40.2</td>\n",
       "      <td>24.8</td>\n",
       "      <td>...</td>\n",
       "      <td>17.8</td>\n",
       "      <td>7.9</td>\n",
       "      <td>6.9</td>\n",
       "      <td>47.5</td>\n",
       "      <td>122.8</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-10-20</td>\n",
       "      <td>2017-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5702</th>\n",
       "      <td>Orlando Magic</td>\n",
       "      <td>Miami Heat</td>\n",
       "      <td>22101227</td>\n",
       "      <td>125</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.433</td>\n",
       "      <td>0.329</td>\n",
       "      <td>0.786</td>\n",
       "      <td>44.1</td>\n",
       "      <td>23.6</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>3.3</td>\n",
       "      <td>4.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>108.2</td>\n",
       "      <td>0.584</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-04-10</td>\n",
       "      <td>2021-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5703</th>\n",
       "      <td>Denver Nuggets</td>\n",
       "      <td>Los Angeles Lakers</td>\n",
       "      <td>22101220</td>\n",
       "      <td>141</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.482</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.796</td>\n",
       "      <td>44.6</td>\n",
       "      <td>28.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.3</td>\n",
       "      <td>7.5</td>\n",
       "      <td>5.1</td>\n",
       "      <td>-3.1</td>\n",
       "      <td>109.7</td>\n",
       "      <td>112.7</td>\n",
       "      <td>0.566</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-04-10</td>\n",
       "      <td>2021-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5704</th>\n",
       "      <td>Memphis Grizzlies</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>22101223</td>\n",
       "      <td>110</td>\n",
       "      <td>0.691</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.735</td>\n",
       "      <td>48.7</td>\n",
       "      <td>25.7</td>\n",
       "      <td>...</td>\n",
       "      <td>13.8</td>\n",
       "      <td>7.4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>113.3</td>\n",
       "      <td>106.2</td>\n",
       "      <td>0.577</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-04-10</td>\n",
       "      <td>2021-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5705</th>\n",
       "      <td>Philadelphia 76ers</td>\n",
       "      <td>Detroit Pistons</td>\n",
       "      <td>22101228</td>\n",
       "      <td>118</td>\n",
       "      <td>0.617</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.820</td>\n",
       "      <td>43.5</td>\n",
       "      <td>24.4</td>\n",
       "      <td>...</td>\n",
       "      <td>14.2</td>\n",
       "      <td>7.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>-7.7</td>\n",
       "      <td>105.5</td>\n",
       "      <td>113.2</td>\n",
       "      <td>0.533</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-04-10</td>\n",
       "      <td>2021-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5706</th>\n",
       "      <td>Minnesota Timberwolves</td>\n",
       "      <td>Chicago Bulls</td>\n",
       "      <td>22101224</td>\n",
       "      <td>120</td>\n",
       "      <td>0.568</td>\n",
       "      <td>0.457</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.778</td>\n",
       "      <td>43.5</td>\n",
       "      <td>25.2</td>\n",
       "      <td>...</td>\n",
       "      <td>12.8</td>\n",
       "      <td>7.2</td>\n",
       "      <td>4.2</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>112.6</td>\n",
       "      <td>113.1</td>\n",
       "      <td>0.578</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-04-10</td>\n",
       "      <td>2021-22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5707 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Home                    Away   Game_ID  H_Score  \\\n",
       "0         Philadelphia 76ers          Boston Celtics  21700019       92   \n",
       "1               Phoenix Suns      Los Angeles Lakers  21700026      130   \n",
       "2              Brooklyn Nets           Orlando Magic  21700022      126   \n",
       "3            Milwaukee Bucks     Cleveland Cavaliers  21700021       97   \n",
       "4             Indiana Pacers  Portland Trail Blazers  21700018       96   \n",
       "...                      ...                     ...       ...      ...   \n",
       "5702           Orlando Magic              Miami Heat  22101227      125   \n",
       "5703          Denver Nuggets      Los Angeles Lakers  22101220      141   \n",
       "5704       Memphis Grizzlies          Boston Celtics  22101223      110   \n",
       "5705      Philadelphia 76ers         Detroit Pistons  22101228      118   \n",
       "5706  Minnesota Timberwolves           Chicago Bulls  22101224      120   \n",
       "\n",
       "      H_W_PCT  H_FG_PCT  H_FG3_PCT  H_FT_PCT  H_REB  H_AST  ...  A_TOV  A_STL  \\\n",
       "0       0.000     0.462      0.429     0.737   45.3   23.6  ...   13.5   11.5   \n",
       "1       0.000     0.315      0.259     0.722   33.0   10.0  ...   19.0    7.6   \n",
       "2       0.000     0.479      0.400     0.906   37.4   19.1  ...   14.4    7.7   \n",
       "3       1.000     0.500      0.333     0.833   45.0   19.0  ...   17.3    3.1   \n",
       "4       1.000     0.520      0.265     0.781   40.2   24.8  ...   17.8    7.9   \n",
       "...       ...       ...        ...       ...    ...    ...  ...    ...    ...   \n",
       "5702    0.259     0.433      0.329     0.786   44.1   23.6  ...   15.0    7.6   \n",
       "5703    0.593     0.482      0.353     0.796   44.6   28.0  ...   14.3    7.5   \n",
       "5704    0.691     0.462      0.353     0.735   48.7   25.7  ...   13.8    7.4   \n",
       "5705    0.617     0.465      0.366     0.820   43.5   24.4  ...   14.2    7.8   \n",
       "5706    0.568     0.457      0.358     0.778   43.5   25.2  ...   12.8    7.2   \n",
       "\n",
       "      A_BLK  A_PLUS_MINUS  A_OFF_RATING  A_DEF_RATING  A_TS_PCT  Result  \\\n",
       "0       3.0          -5.5          99.5         106.1     0.499       0   \n",
       "1       6.7         -15.2          87.6         101.9     0.455       0   \n",
       "2       8.7           6.7         111.5         103.8     0.564       1   \n",
       "3       4.1           3.1         104.1         100.0     0.543       0   \n",
       "4       6.9          47.5         122.8          76.0     0.606       0   \n",
       "...     ...           ...           ...           ...       ...     ...   \n",
       "5702    3.3           4.8         113.0         108.2     0.584       1   \n",
       "5703    5.1          -3.1         109.7         112.7     0.566       0   \n",
       "5704    6.0           7.1         113.3         106.2     0.577       0   \n",
       "5705    4.8          -7.7         105.5         113.2     0.533       1   \n",
       "5706    4.2          -0.4         112.6         113.1     0.578       0   \n",
       "\n",
       "           Date   Season  \n",
       "0    2017-10-20  2017-18  \n",
       "1    2017-10-20  2017-18  \n",
       "2    2017-10-20  2017-18  \n",
       "3    2017-10-20  2017-18  \n",
       "4    2017-10-20  2017-18  \n",
       "...         ...      ...  \n",
       "5702 2022-04-10  2021-22  \n",
       "5703 2022-04-10  2021-22  \n",
       "5704 2022-04-10  2021-22  \n",
       "5705 2022-04-10  2021-22  \n",
       "5706 2022-04-10  2021-22  \n",
       "\n",
       "[5707 rows x 34 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames = [df_2016_final, df_2017_final, df_2018, df_2019_final, df_2021_final, df_2022_final]\n",
    "df = pd.concat(frames)\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Home            0\n",
       "Away            0\n",
       "Game_ID         0\n",
       "H_Score         0\n",
       "H_W_PCT         0\n",
       "H_FG_PCT        0\n",
       "H_FG3_PCT       0\n",
       "H_FT_PCT        0\n",
       "H_REB           0\n",
       "H_AST           0\n",
       "H_TOV           0\n",
       "H_STL           0\n",
       "H_BLK           0\n",
       "H_PLUS_MINUS    0\n",
       "H_OFF_RATING    0\n",
       "H_DEF_RATING    0\n",
       "H_TS_PCT        0\n",
       "A_Score         0\n",
       "A_W_PCT         0\n",
       "A_FG_PCT        0\n",
       "A_FG3_PCT       0\n",
       "A_FT_PCT        0\n",
       "A_REB           0\n",
       "A_AST           0\n",
       "A_TOV           0\n",
       "A_STL           0\n",
       "A_BLK           0\n",
       "A_PLUS_MINUS    0\n",
       "A_OFF_RATING    0\n",
       "A_DEF_RATING    0\n",
       "A_TS_PCT        0\n",
       "Result          0\n",
       "Date            0\n",
       "Season          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Home</th>\n",
       "      <th>Away</th>\n",
       "      <th>Game_ID</th>\n",
       "      <th>H_Score</th>\n",
       "      <th>H_W_PCT</th>\n",
       "      <th>H_FG_PCT</th>\n",
       "      <th>H_FG3_PCT</th>\n",
       "      <th>H_FT_PCT</th>\n",
       "      <th>H_REB</th>\n",
       "      <th>H_AST</th>\n",
       "      <th>...</th>\n",
       "      <th>A_TOV</th>\n",
       "      <th>A_STL</th>\n",
       "      <th>A_BLK</th>\n",
       "      <th>A_PLUS_MINUS</th>\n",
       "      <th>A_OFF_RATING</th>\n",
       "      <th>A_DEF_RATING</th>\n",
       "      <th>A_TS_PCT</th>\n",
       "      <th>Result</th>\n",
       "      <th>Date</th>\n",
       "      <th>Season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Home, Away, Game_ID, H_Score, H_W_PCT, H_FG_PCT, H_FG3_PCT, H_FT_PCT, H_REB, H_AST, H_TOV, H_STL, H_BLK, H_PLUS_MINUS, H_OFF_RATING, H_DEF_RATING, H_TS_PCT, A_Score, A_W_PCT, A_FG_PCT, A_FG3_PCT, A_FT_PCT, A_REB, A_AST, A_TOV, A_STL, A_BLK, A_PLUS_MINUS, A_OFF_RATING, A_DEF_RATING, A_TS_PCT, Result, Date, Season]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 34 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicates = df[df.duplicated()]\n",
    "duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Last N Games Win %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Home  Result\n",
      "5621  Golden State Warriors       0\n",
      "5641  Golden State Warriors       1\n",
      "5677  Golden State Warriors       1\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "prev_game_df = df[df['Date'] < '12/25/2022'][(df['Home'] == \"Golden State Warriors\") | (df['Away'] == 'Golden State Warriors')].sort_values(by = 'Date').tail(10)\n",
    "prev_game_df\n",
    "h_df = prev_game_df.iloc[:, range(0, 32, 31)]\n",
    "\n",
    "h_df = h_df.loc[h_df['Home'] == 'Golden State Warriors'] \n",
    "print(h_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_avg_win_pct_last_n_games(team, game_date, df, n):\n",
    "    prev_game_df = df[df['Date'] < game_date][(df['Home'] == team) | (df['Away'] == team)].sort_values(by = 'Date').tail(n)\n",
    "    \n",
    "    wins = 0 \n",
    "    \n",
    "    result_df = prev_game_df.iloc[:, range(0,32,31)]\n",
    "    h_df = result_df.loc[result_df['Home'] == team] \n",
    "    \n",
    "    h_wins = h_df.loc[h_df['Result'] == 1]\n",
    "    \n",
    "    wins += len(h_wins)\n",
    "      \n",
    "    a_df = result_df.loc[result_df['Home'] != team]\n",
    "    a_wins = a_df.loc[a_df['Result'] == 0]\n",
    "    \n",
    "    wins += len(a_wins)\n",
    "\n",
    "    return wins/n\n",
    "get_avg_win_pct_last_n_games('Golden State Warriors', '12/25/2022', df, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for season in df['Season'].unique() :\n",
    "    \n",
    "    season_stats = df[df['Season'] == season].sort_values(by='Date').reset_index(drop=True)\n",
    "    \n",
    "    for index, row in df.iterrows() : \n",
    "        game_id = row['Game_ID']\n",
    "        game_date = row['Date']\n",
    "        h_team = row['Home']\n",
    "        a_team = row['Away']\n",
    "        \n",
    "        df.loc[index,'Home_W_Pct_10'] = get_avg_win_pct_last_n_games(h_team, game_date, df, 10)\n",
    "        \n",
    "        df.loc[index,'Away_W_Pct_10'] = get_avg_win_pct_last_n_games(a_team, game_date, df, 10)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Home</th>\n",
       "      <th>Away</th>\n",
       "      <th>Game_ID</th>\n",
       "      <th>H_Score</th>\n",
       "      <th>H_W_PCT</th>\n",
       "      <th>H_FG_PCT</th>\n",
       "      <th>H_FG3_PCT</th>\n",
       "      <th>H_FT_PCT</th>\n",
       "      <th>H_REB</th>\n",
       "      <th>H_AST</th>\n",
       "      <th>...</th>\n",
       "      <th>A_BLK</th>\n",
       "      <th>A_PLUS_MINUS</th>\n",
       "      <th>A_OFF_RATING</th>\n",
       "      <th>A_DEF_RATING</th>\n",
       "      <th>A_TS_PCT</th>\n",
       "      <th>Result</th>\n",
       "      <th>Date</th>\n",
       "      <th>Season</th>\n",
       "      <th>Home_W_Pct_10</th>\n",
       "      <th>Away_W_Pct_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5702</th>\n",
       "      <td>Orlando Magic</td>\n",
       "      <td>Miami Heat</td>\n",
       "      <td>22101227</td>\n",
       "      <td>125</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.433</td>\n",
       "      <td>0.329</td>\n",
       "      <td>0.786</td>\n",
       "      <td>44.1</td>\n",
       "      <td>23.6</td>\n",
       "      <td>...</td>\n",
       "      <td>3.3</td>\n",
       "      <td>4.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>108.2</td>\n",
       "      <td>0.584</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-04-10</td>\n",
       "      <td>2021-22</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5703</th>\n",
       "      <td>Denver Nuggets</td>\n",
       "      <td>Los Angeles Lakers</td>\n",
       "      <td>22101220</td>\n",
       "      <td>141</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.482</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.796</td>\n",
       "      <td>44.6</td>\n",
       "      <td>28.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.1</td>\n",
       "      <td>-3.1</td>\n",
       "      <td>109.7</td>\n",
       "      <td>112.7</td>\n",
       "      <td>0.566</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-04-10</td>\n",
       "      <td>2021-22</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5704</th>\n",
       "      <td>Memphis Grizzlies</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>22101223</td>\n",
       "      <td>110</td>\n",
       "      <td>0.691</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.735</td>\n",
       "      <td>48.7</td>\n",
       "      <td>25.7</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>113.3</td>\n",
       "      <td>106.2</td>\n",
       "      <td>0.577</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-04-10</td>\n",
       "      <td>2021-22</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5705</th>\n",
       "      <td>Philadelphia 76ers</td>\n",
       "      <td>Detroit Pistons</td>\n",
       "      <td>22101228</td>\n",
       "      <td>118</td>\n",
       "      <td>0.617</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.820</td>\n",
       "      <td>43.5</td>\n",
       "      <td>24.4</td>\n",
       "      <td>...</td>\n",
       "      <td>4.8</td>\n",
       "      <td>-7.7</td>\n",
       "      <td>105.5</td>\n",
       "      <td>113.2</td>\n",
       "      <td>0.533</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-04-10</td>\n",
       "      <td>2021-22</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5706</th>\n",
       "      <td>Minnesota Timberwolves</td>\n",
       "      <td>Chicago Bulls</td>\n",
       "      <td>22101224</td>\n",
       "      <td>120</td>\n",
       "      <td>0.568</td>\n",
       "      <td>0.457</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.778</td>\n",
       "      <td>43.5</td>\n",
       "      <td>25.2</td>\n",
       "      <td>...</td>\n",
       "      <td>4.2</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>112.6</td>\n",
       "      <td>113.1</td>\n",
       "      <td>0.578</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-04-10</td>\n",
       "      <td>2021-22</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Home                Away   Game_ID  H_Score  H_W_PCT  \\\n",
       "5702           Orlando Magic          Miami Heat  22101227      125    0.259   \n",
       "5703          Denver Nuggets  Los Angeles Lakers  22101220      141    0.593   \n",
       "5704       Memphis Grizzlies      Boston Celtics  22101223      110    0.691   \n",
       "5705      Philadelphia 76ers     Detroit Pistons  22101228      118    0.617   \n",
       "5706  Minnesota Timberwolves       Chicago Bulls  22101224      120    0.568   \n",
       "\n",
       "      H_FG_PCT  H_FG3_PCT  H_FT_PCT  H_REB  H_AST  ...  A_BLK  A_PLUS_MINUS  \\\n",
       "5702     0.433      0.329     0.786   44.1   23.6  ...    3.3           4.8   \n",
       "5703     0.482      0.353     0.796   44.6   28.0  ...    5.1          -3.1   \n",
       "5704     0.462      0.353     0.735   48.7   25.7  ...    6.0           7.1   \n",
       "5705     0.465      0.366     0.820   43.5   24.4  ...    4.8          -7.7   \n",
       "5706     0.457      0.358     0.778   43.5   25.2  ...    4.2          -0.4   \n",
       "\n",
       "      A_OFF_RATING  A_DEF_RATING  A_TS_PCT  Result       Date   Season  \\\n",
       "5702         113.0         108.2     0.584       1 2022-04-10  2021-22   \n",
       "5703         109.7         112.7     0.566       0 2022-04-10  2021-22   \n",
       "5704         113.3         106.2     0.577       0 2022-04-10  2021-22   \n",
       "5705         105.5         113.2     0.533       1 2022-04-10  2021-22   \n",
       "5706         112.6         113.1     0.578       0 2022-04-10  2021-22   \n",
       "\n",
       "      Home_W_Pct_10  Away_W_Pct_10  \n",
       "5702            0.3            0.6  \n",
       "5703            0.6            0.2  \n",
       "5704            0.8            0.7  \n",
       "5705            0.6            0.4  \n",
       "5706            0.5            0.3  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Season'] == '2021-22'].tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELO Rating\n",
    "- every team starts with a 1500\n",
    "$$R_{i+1} = k * (S_{team} - E_{team} + R_{i})$$\n",
    "- S team is 1 if the team wins and 0 if they lose\n",
    "- E team is the expected win probability of the team \n",
    "$$E_{team} = \\frac{1}{1+10^{\\frac{opp\\_elo - team\\_elo}{400}}}$$\n",
    "- k is a moving constant that depends on margin of victory and difference in Elo ratings\n",
    "$$k = 20\\frac{(MOV_{winner} + 3)^{0.8}}{7.5 + 0.006(elo\\_difference_{winner})} $$\n",
    "- team year by year carryover \n",
    "$$(R * 0.75) + (0.25 * 1505)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Home</th>\n",
       "      <th>Away</th>\n",
       "      <th>Game_ID</th>\n",
       "      <th>H_Score</th>\n",
       "      <th>H_W_PCT</th>\n",
       "      <th>H_FG_PCT</th>\n",
       "      <th>H_FG3_PCT</th>\n",
       "      <th>H_FT_PCT</th>\n",
       "      <th>H_REB</th>\n",
       "      <th>H_AST</th>\n",
       "      <th>...</th>\n",
       "      <th>A_BLK</th>\n",
       "      <th>A_PLUS_MINUS</th>\n",
       "      <th>A_OFF_RATING</th>\n",
       "      <th>A_DEF_RATING</th>\n",
       "      <th>A_TS_PCT</th>\n",
       "      <th>Result</th>\n",
       "      <th>Date</th>\n",
       "      <th>Season</th>\n",
       "      <th>Home_W_Pct_10</th>\n",
       "      <th>Away_W_Pct_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Philadelphia 76ers</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>21700019</td>\n",
       "      <td>92</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.737</td>\n",
       "      <td>45.3</td>\n",
       "      <td>23.6</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-5.5</td>\n",
       "      <td>99.5</td>\n",
       "      <td>106.1</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-10-20</td>\n",
       "      <td>2017-18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Phoenix Suns</td>\n",
       "      <td>Los Angeles Lakers</td>\n",
       "      <td>21700026</td>\n",
       "      <td>130</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.722</td>\n",
       "      <td>33.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.7</td>\n",
       "      <td>-15.2</td>\n",
       "      <td>87.6</td>\n",
       "      <td>101.9</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-10-20</td>\n",
       "      <td>2017-18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brooklyn Nets</td>\n",
       "      <td>Orlando Magic</td>\n",
       "      <td>21700022</td>\n",
       "      <td>126</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.479</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.906</td>\n",
       "      <td>37.4</td>\n",
       "      <td>19.1</td>\n",
       "      <td>...</td>\n",
       "      <td>8.7</td>\n",
       "      <td>6.7</td>\n",
       "      <td>111.5</td>\n",
       "      <td>103.8</td>\n",
       "      <td>0.564</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-10-20</td>\n",
       "      <td>2017-18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Milwaukee Bucks</td>\n",
       "      <td>Cleveland Cavaliers</td>\n",
       "      <td>21700021</td>\n",
       "      <td>97</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.833</td>\n",
       "      <td>45.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>104.1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.543</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-10-20</td>\n",
       "      <td>2017-18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Indiana Pacers</td>\n",
       "      <td>Portland Trail Blazers</td>\n",
       "      <td>21700018</td>\n",
       "      <td>96</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.781</td>\n",
       "      <td>40.2</td>\n",
       "      <td>24.8</td>\n",
       "      <td>...</td>\n",
       "      <td>6.9</td>\n",
       "      <td>47.5</td>\n",
       "      <td>122.8</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-10-20</td>\n",
       "      <td>2017-18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Home                    Away   Game_ID  H_Score  H_W_PCT  \\\n",
       "0  Philadelphia 76ers          Boston Celtics  21700019       92      0.0   \n",
       "1        Phoenix Suns      Los Angeles Lakers  21700026      130      0.0   \n",
       "2       Brooklyn Nets           Orlando Magic  21700022      126      0.0   \n",
       "3     Milwaukee Bucks     Cleveland Cavaliers  21700021       97      1.0   \n",
       "4      Indiana Pacers  Portland Trail Blazers  21700018       96      1.0   \n",
       "\n",
       "   H_FG_PCT  H_FG3_PCT  H_FT_PCT  H_REB  H_AST  ...  A_BLK  A_PLUS_MINUS  \\\n",
       "0     0.462      0.429     0.737   45.3   23.6  ...    3.0          -5.5   \n",
       "1     0.315      0.259     0.722   33.0   10.0  ...    6.7         -15.2   \n",
       "2     0.479      0.400     0.906   37.4   19.1  ...    8.7           6.7   \n",
       "3     0.500      0.333     0.833   45.0   19.0  ...    4.1           3.1   \n",
       "4     0.520      0.265     0.781   40.2   24.8  ...    6.9          47.5   \n",
       "\n",
       "   A_OFF_RATING  A_DEF_RATING  A_TS_PCT  Result       Date   Season  \\\n",
       "0          99.5         106.1     0.499       0 2017-10-20  2017-18   \n",
       "1          87.6         101.9     0.455       0 2017-10-20  2017-18   \n",
       "2         111.5         103.8     0.564       1 2017-10-20  2017-18   \n",
       "3         104.1         100.0     0.543       0 2017-10-20  2017-18   \n",
       "4         122.8          76.0     0.606       0 2017-10-20  2017-18   \n",
       "\n",
       "   Home_W_Pct_10  Away_W_Pct_10  \n",
       "0            0.0            0.0  \n",
       "1            0.0            0.0  \n",
       "2            0.0            0.0  \n",
       "3            0.0            0.0  \n",
       "4            0.0            0.0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Home and road team win probabilities implied by Elo ratings and home court adjustment \n",
    "import math\n",
    "import time\n",
    "def win_probs(home_elo, away_elo, home_court_advantage) :\n",
    "    h = math.pow(10, home_elo/400)\n",
    "    r = math.pow(10, away_elo/400)\n",
    "    a = math.pow(10, home_court_advantage/400) \n",
    "\n",
    "    denom = r + a*h\n",
    "    home_prob = a*h / denom\n",
    "    away_prob = r / denom \n",
    "  \n",
    "    return home_prob, away_prob\n",
    "\n",
    "  #odds the home team will win based on elo ratings and home court advantage\n",
    "\n",
    "def home_odds_on(home_elo, away_elo, home_court_advantage) :\n",
    "    h = math.pow(10, home_elo/400)\n",
    "    r = math.pow(10, away_elo/400)\n",
    "    a = math.pow(10, home_court_advantage/400)\n",
    "    return a*h/r\n",
    "\n",
    "#this function determines the constant used in the elo rating, based on margin of victory and difference in elo ratings\n",
    "def elo_k(MOV, elo_diff):\n",
    "    k = 20 # Optimal K is 20 https://fivethirtyeight.com/features/how-we-calculate-nba-elo-ratings/\n",
    "    if MOV>0:\n",
    "        multiplier=(MOV+3)**(0.8)/(7.5+0.006*(elo_diff))\n",
    "    else:\n",
    "        multiplier=(-MOV+3)**(0.8)/(7.5+0.006*(-elo_diff))\n",
    "    return k*multiplier\n",
    "\n",
    "\n",
    "# Updates the home and away teams elo ratings after a game \n",
    "\n",
    "def update_elo(home_score, away_score, home_elo, away_elo, home_court_advantage) :\n",
    "    home_prob, away_prob = win_probs(home_elo, away_elo, home_court_advantage) \n",
    "\n",
    "    if (home_score - away_score > 0) :\n",
    "        home_win = 1 \n",
    "        away_win = 0 \n",
    "    else :\n",
    "        home_win = 0 \n",
    "        away_win = 1 \n",
    "  \n",
    "    k = elo_k(home_score - away_score, home_elo - away_elo)\n",
    "\n",
    "    updated_home_elo = home_elo + k * (home_win - home_prob) \n",
    "    updated_away_elo = away_elo + k * (away_win - away_prob)\n",
    "    \n",
    "    return updated_home_elo, updated_away_elo\n",
    "\n",
    "\n",
    "# Takes into account prev season elo\n",
    "# The reason we revert to a mean of 1505 rather than 1500 is that \n",
    "# there are liable to be a couple of relatively recent expansion teams in the league at any given time\n",
    "def get_prev_elo(team, date, season, team_stats, elo_df) :\n",
    "    prev_game = team_stats[team_stats['Date'] < game_date][(team_stats['Home'] == team) | (team_stats['Away'] == team)].sort_values(by = 'Date').tail(1).iloc[0] \n",
    "\n",
    "    if team == prev_game['Home'] :\n",
    "        elo_rating = elo_df[elo_df['Game_ID'] == prev_game['Game_ID']]['H_Team_Elo_After'].values[0]\n",
    "    else :\n",
    "        elo_rating = elo_df[elo_df['Game_ID'] == prev_game['Game_ID']]['A_Team_Elo_After'].values[0]\n",
    "  \n",
    "    if prev_game['Season'] != season :\n",
    "        return (0.75 * elo_rating) + (0.25 * 1505) # Year-to-Year Carry-Over\n",
    "    else :\n",
    "        return elo_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by = 'Date', inplace = True)\n",
    "df.reset_index(inplace=True, drop = True)\n",
    "elo_df = pd.DataFrame(columns=['Game_ID', 'H_Team', 'A_Team', 'H_Team_Elo_Before', 'A_Team_Elo_Before', 'H_Team_Elo_After', 'A_Team_Elo_After'])\n",
    "teams_elo_df = pd.DataFrame(columns=['Game_ID','Team', 'Elo', 'Date', 'Where_Played', 'Season']) \n",
    "\n",
    "for index, row in df.iterrows(): \n",
    "    game_id = row['Game_ID']\n",
    "    game_date = row['Date']\n",
    "    season = row['Season']\n",
    "    h_team, a_team = row['Home'], row['Away']\n",
    "    h_score, a_score = row['H_Score'], row['A_Score'] \n",
    "\n",
    "    if (h_team not in elo_df['H_Team'].values and h_team not in elo_df['A_Team'].values) :\n",
    "        h_team_elo_before = 1500\n",
    "    else :\n",
    "        h_team_elo_before = get_prev_elo(h_team, game_date, season, df, elo_df)\n",
    "\n",
    "    if (a_team not in elo_df['H_Team'].values and a_team not in elo_df['A_Team'].values) :\n",
    "        a_team_elo_before = 1500\n",
    "    else :\n",
    "        a_team_elo_before = get_prev_elo(a_team, game_date, season, df, elo_df)\n",
    "\n",
    "    h_team_elo_after, a_team_elo_after = update_elo(h_score, a_score, h_team_elo_before, a_team_elo_before, 69)\n",
    "\n",
    "    new_row = {'Game_ID': game_id, 'H_Team': h_team, 'A_Team': a_team, 'H_Team_Elo_Before': h_team_elo_before, 'A_Team_Elo_Before': a_team_elo_before, \\\n",
    "                                                                        'H_Team_Elo_After' : h_team_elo_after, 'A_Team_Elo_After': a_team_elo_after}\n",
    "    teams_row_one = {'Game_ID': game_id,'Team': h_team, 'Elo': h_team_elo_before, 'Date': game_date, 'Where_Played': 'Home', 'Season': season}\n",
    "    teams_row_two = {'Game_ID': game_id,'Team': a_team, 'Elo': a_team_elo_before, 'Date': game_date, 'Where_Played': 'Away', 'Season': season}\n",
    "  \n",
    "    elo_df = elo_df.append(new_row, ignore_index = True)\n",
    "    teams_elo_df = teams_elo_df.append(teams_row_one, ignore_index=True)\n",
    "    teams_elo_df = teams_elo_df.append(teams_row_two, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Game_ID</th>\n",
       "      <th>H_Team</th>\n",
       "      <th>A_Team</th>\n",
       "      <th>H_Team_Elo_Before</th>\n",
       "      <th>A_Team_Elo_Before</th>\n",
       "      <th>H_Team_Elo_After</th>\n",
       "      <th>A_Team_Elo_After</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21700019</td>\n",
       "      <td>Philadelphia 76ers</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>1500</td>\n",
       "      <td>1500</td>\n",
       "      <td>1487.588205</td>\n",
       "      <td>1512.411795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21700026</td>\n",
       "      <td>Phoenix Suns</td>\n",
       "      <td>Los Angeles Lakers</td>\n",
       "      <td>1500</td>\n",
       "      <td>1500</td>\n",
       "      <td>1494.220957</td>\n",
       "      <td>1505.779043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21700022</td>\n",
       "      <td>Brooklyn Nets</td>\n",
       "      <td>Orlando Magic</td>\n",
       "      <td>1500</td>\n",
       "      <td>1500</td>\n",
       "      <td>1505.657856</td>\n",
       "      <td>1494.342144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21700021</td>\n",
       "      <td>Milwaukee Bucks</td>\n",
       "      <td>Cleveland Cavaliers</td>\n",
       "      <td>1500</td>\n",
       "      <td>1500</td>\n",
       "      <td>1481.093199</td>\n",
       "      <td>1518.906801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21700018</td>\n",
       "      <td>Indiana Pacers</td>\n",
       "      <td>Portland Trail Blazers</td>\n",
       "      <td>1500</td>\n",
       "      <td>1500</td>\n",
       "      <td>1481.783902</td>\n",
       "      <td>1518.216098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5702</th>\n",
       "      <td>22101225</td>\n",
       "      <td>New Orleans Pelicans</td>\n",
       "      <td>Golden State Warriors</td>\n",
       "      <td>1534.445418</td>\n",
       "      <td>1574.302989</td>\n",
       "      <td>1516.647138</td>\n",
       "      <td>1592.101269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5703</th>\n",
       "      <td>22101219</td>\n",
       "      <td>Dallas Mavericks</td>\n",
       "      <td>San Antonio Spurs</td>\n",
       "      <td>1585.484564</td>\n",
       "      <td>1490.992295</td>\n",
       "      <td>1590.900483</td>\n",
       "      <td>1485.576375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5704</th>\n",
       "      <td>22101222</td>\n",
       "      <td>LA Clippers</td>\n",
       "      <td>Oklahoma City Thunder</td>\n",
       "      <td>1526.825496</td>\n",
       "      <td>1338.090516</td>\n",
       "      <td>1537.08683</td>\n",
       "      <td>1327.829182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5705</th>\n",
       "      <td>22101217</td>\n",
       "      <td>Charlotte Hornets</td>\n",
       "      <td>Washington Wizards</td>\n",
       "      <td>1539.195491</td>\n",
       "      <td>1428.163212</td>\n",
       "      <td>1545.957475</td>\n",
       "      <td>1421.401228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5706</th>\n",
       "      <td>22101224</td>\n",
       "      <td>Minnesota Timberwolves</td>\n",
       "      <td>Chicago Bulls</td>\n",
       "      <td>1574.46694</td>\n",
       "      <td>1450.007328</td>\n",
       "      <td>1563.891946</td>\n",
       "      <td>1460.582322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5707 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Game_ID                  H_Team                  A_Team  \\\n",
       "0     21700019      Philadelphia 76ers          Boston Celtics   \n",
       "1     21700026            Phoenix Suns      Los Angeles Lakers   \n",
       "2     21700022           Brooklyn Nets           Orlando Magic   \n",
       "3     21700021         Milwaukee Bucks     Cleveland Cavaliers   \n",
       "4     21700018          Indiana Pacers  Portland Trail Blazers   \n",
       "...        ...                     ...                     ...   \n",
       "5702  22101225    New Orleans Pelicans   Golden State Warriors   \n",
       "5703  22101219        Dallas Mavericks       San Antonio Spurs   \n",
       "5704  22101222             LA Clippers   Oklahoma City Thunder   \n",
       "5705  22101217       Charlotte Hornets      Washington Wizards   \n",
       "5706  22101224  Minnesota Timberwolves           Chicago Bulls   \n",
       "\n",
       "     H_Team_Elo_Before A_Team_Elo_Before H_Team_Elo_After A_Team_Elo_After  \n",
       "0                 1500              1500      1487.588205      1512.411795  \n",
       "1                 1500              1500      1494.220957      1505.779043  \n",
       "2                 1500              1500      1505.657856      1494.342144  \n",
       "3                 1500              1500      1481.093199      1518.906801  \n",
       "4                 1500              1500      1481.783902      1518.216098  \n",
       "...                ...               ...              ...              ...  \n",
       "5702       1534.445418       1574.302989      1516.647138      1592.101269  \n",
       "5703       1585.484564       1490.992295      1590.900483      1485.576375  \n",
       "5704       1526.825496       1338.090516       1537.08683      1327.829182  \n",
       "5705       1539.195491       1428.163212      1545.957475      1421.401228  \n",
       "5706        1574.46694       1450.007328      1563.891946      1460.582322  \n",
       "\n",
       "[5707 rows x 7 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#teams_elo_df.set_index([\"Team\"], append=True)\n",
    "#dataset = teams_elo_df.pivot(index=\"Team\",values=\"Elo\", columns=\"Date\")\n",
    "dates = list(set([d.strftime(\"%m-%d-%Y\") for d in teams_elo_df[\"Date\"]]))\n",
    "dates = sorted(dates, key=lambda x: time.strptime(x, '%m-%d-%Y'))\n",
    "teams = df[\"Away\"]\n",
    "dataset = pd.DataFrame(columns=dates)\n",
    "dataset[\"Team\"] = teams.drop_duplicates()\n",
    "dataset = dataset.set_index(\"Team\")\n",
    "\n",
    "for index, row in teams_elo_df.iterrows():\n",
    "    date = row[\"Date\"].strftime(\"%m-%d-%Y\")\n",
    "    team = row[\"Team\"]\n",
    "    elo = row[\"Elo\"]\n",
    "    dataset[date][team] = elo\n",
    "\n",
    "teams_elo_df['Elo'] = teams_elo_df['Elo'].astype(float)\n",
    "\n",
    "elo_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Home</th>\n",
       "      <th>Away</th>\n",
       "      <th>Game_ID</th>\n",
       "      <th>H_Score</th>\n",
       "      <th>H_W_PCT</th>\n",
       "      <th>H_FG_PCT</th>\n",
       "      <th>H_FG3_PCT</th>\n",
       "      <th>H_FT_PCT</th>\n",
       "      <th>H_REB</th>\n",
       "      <th>H_AST</th>\n",
       "      <th>...</th>\n",
       "      <th>A_TS_PCT</th>\n",
       "      <th>Result</th>\n",
       "      <th>Date</th>\n",
       "      <th>Season</th>\n",
       "      <th>Home_W_Pct_10</th>\n",
       "      <th>Away_W_Pct_10</th>\n",
       "      <th>H_Team_Elo_Before</th>\n",
       "      <th>A_Team_Elo_Before</th>\n",
       "      <th>H_Team_Elo_After</th>\n",
       "      <th>A_Team_Elo_After</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Philadelphia 76ers</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>21700019</td>\n",
       "      <td>92</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.737</td>\n",
       "      <td>45.3</td>\n",
       "      <td>23.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-10-20</td>\n",
       "      <td>2017-18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500</td>\n",
       "      <td>1500</td>\n",
       "      <td>1487.588205</td>\n",
       "      <td>1512.411795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Phoenix Suns</td>\n",
       "      <td>Los Angeles Lakers</td>\n",
       "      <td>21700026</td>\n",
       "      <td>130</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.722</td>\n",
       "      <td>33.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-10-20</td>\n",
       "      <td>2017-18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500</td>\n",
       "      <td>1500</td>\n",
       "      <td>1494.220957</td>\n",
       "      <td>1505.779043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brooklyn Nets</td>\n",
       "      <td>Orlando Magic</td>\n",
       "      <td>21700022</td>\n",
       "      <td>126</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.479</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.906</td>\n",
       "      <td>37.4</td>\n",
       "      <td>19.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.564</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-10-20</td>\n",
       "      <td>2017-18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500</td>\n",
       "      <td>1500</td>\n",
       "      <td>1505.657856</td>\n",
       "      <td>1494.342144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Milwaukee Bucks</td>\n",
       "      <td>Cleveland Cavaliers</td>\n",
       "      <td>21700021</td>\n",
       "      <td>97</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.833</td>\n",
       "      <td>45.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.543</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-10-20</td>\n",
       "      <td>2017-18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500</td>\n",
       "      <td>1500</td>\n",
       "      <td>1481.093199</td>\n",
       "      <td>1518.906801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Indiana Pacers</td>\n",
       "      <td>Portland Trail Blazers</td>\n",
       "      <td>21700018</td>\n",
       "      <td>96</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.781</td>\n",
       "      <td>40.2</td>\n",
       "      <td>24.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-10-20</td>\n",
       "      <td>2017-18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500</td>\n",
       "      <td>1500</td>\n",
       "      <td>1481.783902</td>\n",
       "      <td>1518.216098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Home                    Away   Game_ID  H_Score  H_W_PCT  \\\n",
       "0  Philadelphia 76ers          Boston Celtics  21700019       92      0.0   \n",
       "1        Phoenix Suns      Los Angeles Lakers  21700026      130      0.0   \n",
       "2       Brooklyn Nets           Orlando Magic  21700022      126      0.0   \n",
       "3     Milwaukee Bucks     Cleveland Cavaliers  21700021       97      1.0   \n",
       "4      Indiana Pacers  Portland Trail Blazers  21700018       96      1.0   \n",
       "\n",
       "   H_FG_PCT  H_FG3_PCT  H_FT_PCT  H_REB  H_AST  ...  A_TS_PCT  Result  \\\n",
       "0     0.462      0.429     0.737   45.3   23.6  ...     0.499       0   \n",
       "1     0.315      0.259     0.722   33.0   10.0  ...     0.455       0   \n",
       "2     0.479      0.400     0.906   37.4   19.1  ...     0.564       1   \n",
       "3     0.500      0.333     0.833   45.0   19.0  ...     0.543       0   \n",
       "4     0.520      0.265     0.781   40.2   24.8  ...     0.606       0   \n",
       "\n",
       "        Date   Season  Home_W_Pct_10  Away_W_Pct_10  H_Team_Elo_Before  \\\n",
       "0 2017-10-20  2017-18            0.0            0.0               1500   \n",
       "1 2017-10-20  2017-18            0.0            0.0               1500   \n",
       "2 2017-10-20  2017-18            0.0            0.0               1500   \n",
       "3 2017-10-20  2017-18            0.0            0.0               1500   \n",
       "4 2017-10-20  2017-18            0.0            0.0               1500   \n",
       "\n",
       "   A_Team_Elo_Before  H_Team_Elo_After  A_Team_Elo_After  \n",
       "0               1500       1487.588205       1512.411795  \n",
       "1               1500       1494.220957       1505.779043  \n",
       "2               1500       1505.657856       1494.342144  \n",
       "3               1500       1481.093199       1518.906801  \n",
       "4               1500       1481.783902       1518.216098  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.merge(elo_df.drop(columns=['H_Team', 'A_Team']), on ='Game_ID')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardization and Z Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Different Models - No Z Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final dataset consists of three seasons and 5707 games.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Home</th>\n",
       "      <th>Away</th>\n",
       "      <th>Game_ID</th>\n",
       "      <th>H_Score</th>\n",
       "      <th>H_W_PCT</th>\n",
       "      <th>H_FG_PCT</th>\n",
       "      <th>H_FG3_PCT</th>\n",
       "      <th>H_FT_PCT</th>\n",
       "      <th>H_REB</th>\n",
       "      <th>H_AST</th>\n",
       "      <th>...</th>\n",
       "      <th>A_TS_PCT</th>\n",
       "      <th>Result</th>\n",
       "      <th>Date</th>\n",
       "      <th>Season</th>\n",
       "      <th>Home_W_Pct_10</th>\n",
       "      <th>Away_W_Pct_10</th>\n",
       "      <th>H_Team_Elo_Before</th>\n",
       "      <th>A_Team_Elo_Before</th>\n",
       "      <th>H_Team_Elo_After</th>\n",
       "      <th>A_Team_Elo_After</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5702</th>\n",
       "      <td>New Orleans Pelicans</td>\n",
       "      <td>Golden State Warriors</td>\n",
       "      <td>22101225</td>\n",
       "      <td>107</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.457</td>\n",
       "      <td>0.332</td>\n",
       "      <td>0.789</td>\n",
       "      <td>46.0</td>\n",
       "      <td>25.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-04-10</td>\n",
       "      <td>2021-22</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1534.445418</td>\n",
       "      <td>1574.302989</td>\n",
       "      <td>1516.647138</td>\n",
       "      <td>1592.101269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5703</th>\n",
       "      <td>Dallas Mavericks</td>\n",
       "      <td>San Antonio Spurs</td>\n",
       "      <td>22101219</td>\n",
       "      <td>130</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.348</td>\n",
       "      <td>0.771</td>\n",
       "      <td>44.8</td>\n",
       "      <td>24.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.556</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-04-10</td>\n",
       "      <td>2021-22</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1585.484564</td>\n",
       "      <td>1490.992295</td>\n",
       "      <td>1590.900483</td>\n",
       "      <td>1485.576375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5704</th>\n",
       "      <td>LA Clippers</td>\n",
       "      <td>Oklahoma City Thunder</td>\n",
       "      <td>22101222</td>\n",
       "      <td>138</td>\n",
       "      <td>0.506</td>\n",
       "      <td>0.457</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.792</td>\n",
       "      <td>44.3</td>\n",
       "      <td>24.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.531</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-04-10</td>\n",
       "      <td>2021-22</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1526.825496</td>\n",
       "      <td>1338.090516</td>\n",
       "      <td>1537.08683</td>\n",
       "      <td>1327.829182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5705</th>\n",
       "      <td>Charlotte Hornets</td>\n",
       "      <td>Washington Wizards</td>\n",
       "      <td>22101217</td>\n",
       "      <td>124</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.363</td>\n",
       "      <td>0.741</td>\n",
       "      <td>43.9</td>\n",
       "      <td>27.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.569</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-04-10</td>\n",
       "      <td>2021-22</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1539.195491</td>\n",
       "      <td>1428.163212</td>\n",
       "      <td>1545.957475</td>\n",
       "      <td>1421.401228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5706</th>\n",
       "      <td>Minnesota Timberwolves</td>\n",
       "      <td>Chicago Bulls</td>\n",
       "      <td>22101224</td>\n",
       "      <td>120</td>\n",
       "      <td>0.568</td>\n",
       "      <td>0.457</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.778</td>\n",
       "      <td>43.5</td>\n",
       "      <td>25.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.578</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-04-10</td>\n",
       "      <td>2021-22</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1574.46694</td>\n",
       "      <td>1450.007328</td>\n",
       "      <td>1563.891946</td>\n",
       "      <td>1460.582322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Home                   Away   Game_ID  H_Score  \\\n",
       "5702    New Orleans Pelicans  Golden State Warriors  22101225      107   \n",
       "5703        Dallas Mavericks      San Antonio Spurs  22101219      130   \n",
       "5704             LA Clippers  Oklahoma City Thunder  22101222      138   \n",
       "5705       Charlotte Hornets     Washington Wizards  22101217      124   \n",
       "5706  Minnesota Timberwolves          Chicago Bulls  22101224      120   \n",
       "\n",
       "      H_W_PCT  H_FG_PCT  H_FG3_PCT  H_FT_PCT  H_REB  H_AST  ...  A_TS_PCT  \\\n",
       "5702    0.444     0.457      0.332     0.789   46.0   25.4  ...     0.580   \n",
       "5703    0.630     0.460      0.348     0.771   44.8   24.2  ...     0.556   \n",
       "5704    0.506     0.457      0.372     0.792   44.3   24.1  ...     0.531   \n",
       "5705    0.519     0.467      0.363     0.741   43.9   27.6  ...     0.569   \n",
       "5706    0.568     0.457      0.358     0.778   43.5   25.2  ...     0.578   \n",
       "\n",
       "      Result       Date   Season  Home_W_Pct_10  Away_W_Pct_10  \\\n",
       "5702       0 2022-04-10  2021-22            0.6            0.5   \n",
       "5703       1 2022-04-10  2021-22            0.8            0.7   \n",
       "5704       1 2022-04-10  2021-22            0.5            0.4   \n",
       "5705       1 2022-04-10  2021-22            0.6            0.5   \n",
       "5706       0 2022-04-10  2021-22            0.5            0.3   \n",
       "\n",
       "      H_Team_Elo_Before  A_Team_Elo_Before  H_Team_Elo_After  A_Team_Elo_After  \n",
       "5702        1534.445418        1574.302989       1516.647138       1592.101269  \n",
       "5703        1585.484564        1490.992295       1590.900483       1485.576375  \n",
       "5704        1526.825496        1338.090516        1537.08683       1327.829182  \n",
       "5705        1539.195491        1428.163212       1545.957475       1421.401228  \n",
       "5706         1574.46694        1450.007328       1563.891946       1460.582322  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_csv(r'C:/Users/alvaro/OneDrive/Documents/School/Flatiron/Projects/NBA_Prediction_Model/data/nba_raw.csv', \n",
    "          index=False)\n",
    "print(f'The final dataset consists of three seasons and {len(df)} games.')\n",
    "df = df.reset_index(drop=True)\n",
    "df.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/nba_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result               1.000000\n",
      "H_Score              0.461871\n",
      "A_Score              0.461385\n",
      "H_Team_Elo_After     0.363042\n",
      "A_Team_Elo_After     0.308683\n",
      "H_Team_Elo_Before    0.266572\n",
      "H_PLUS_MINUS         0.234252\n",
      "Home_W_Pct_10        0.215551\n",
      "H_W_PCT              0.214225\n",
      "A_Team_Elo_Before    0.209484\n",
      "A_W_PCT              0.169454\n",
      "A_PLUS_MINUS         0.169382\n",
      "H_OFF_RATING         0.157338\n",
      "Away_W_Pct_10        0.157198\n",
      "H_TS_PCT             0.154047\n",
      "H_DEF_RATING         0.152833\n",
      "H_FG_PCT             0.140374\n",
      "A_OFF_RATING         0.136559\n",
      "A_TS_PCT             0.129107\n",
      "H_REB                0.114393\n",
      "A_FG_PCT             0.101940\n",
      "H_FG3_PCT            0.090817\n",
      "A_DEF_RATING         0.089300\n",
      "H_AST                0.080855\n",
      "A_REB                0.076496\n",
      "A_AST                0.073782\n",
      "H_BLK                0.072406\n",
      "A_BLK                0.066711\n",
      "H_FT_PCT             0.064787\n",
      "A_FG3_PCT            0.061637\n",
      "A_TOV                0.054370\n",
      "A_FT_PCT             0.051991\n",
      "H_STL                0.041594\n",
      "H_TOV                0.033918\n",
      "Game_ID              0.033395\n",
      "A_STL                0.029415\n",
      "Name: Result, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df.corr()['Result'].abs().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style(\"darkgrid\"):\n",
    "    fig, ax = plt.subplots(figsize=(44, 34))\n",
    "    \n",
    "    mask = np.triu(np.ones_like(df.corr(), dtype=bool))\n",
    "    ax = sns.heatmap(abs(df.corr()),mask=mask,annot=True)\n",
    "    fig.savefig('images/Corelation_Heatmap');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast \"H_Team_Elo_Before\" and \"A_Team_Elo_Before\" as floats\n",
    "df[\"H_Team_Elo_Before\"] = df.H_Team_Elo_Before.astype(float)\n",
    "df[\"A_Team_Elo_Before\"] = df.A_Team_Elo_Before.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns that have data on post-game stats\n",
    "df = df.drop(['H_Team_Elo_After', 'A_Team_Elo_After', 'H_Score', 'A_Score'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove irrelevant columns\n",
    "df = df.drop(['Home', 'Away', 'Game_ID', 'Date', 'Season'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['H_W_PCT', 'H_FG_PCT', 'H_FG3_PCT', 'H_FT_PCT', 'H_REB', 'H_AST',\n",
       "       'H_TOV', 'H_STL', 'H_BLK', 'H_PLUS_MINUS', 'H_OFF_RATING',\n",
       "       'H_DEF_RATING', 'H_TS_PCT', 'A_W_PCT', 'A_FG_PCT', 'A_FG3_PCT',\n",
       "       'A_FT_PCT', 'A_REB', 'A_AST', 'A_TOV', 'A_STL', 'A_BLK', 'A_PLUS_MINUS',\n",
       "       'A_OFF_RATING', 'A_DEF_RATING', 'A_TS_PCT', 'Result', 'Home_W_Pct_10',\n",
       "       'Away_W_Pct_10', 'H_Team_Elo_Before', 'A_Team_Elo_Before'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'C:\\Users\\alvaro\\OneDrive\\Documents\\School\\Flatiron\\Projects\\NBA_Prediction_Model\\data\\nba.csv', \n",
    "          index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/nba.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(44, 34))\n",
    "correlation = df[['H_W_PCT', \n",
    "                  'H_REB', \n",
    "                  'H_AST',\n",
    "                  'H_TOV', \n",
    "                  'H_STL', \n",
    "                  'H_BLK', \n",
    "                  'H_PLUS_MINUS', \n",
    "                  'H_OFF_RATING',\n",
    "                  'H_DEF_RATING', \n",
    "                  'H_TS_PCT', \n",
    "                  'H_Team_Elo_Before', \n",
    "                  'Home_W_Pct_10', \n",
    "                  'Result'\n",
    "                  ]]\n",
    "\n",
    "sns.heatmap(correlation.corr(), annot=True);\n",
    "# correlation\n",
    "# sns.heatmap(df.corr(), annot=True);\n",
    "# sns.heatmap(df['Result'].corr(), annot=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.corr()['Result'].abs().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style(\"darkgrid\"):\n",
    "    fig, ax = plt.subplots(figsize=(44, 34))\n",
    "    \n",
    "    mask = np.triu(np.ones_like(df.corr(), dtype=bool))\n",
    "    ax = sns.heatmap(abs(df.corr()),mask=mask,annot=True)\n",
    "    fig.savefig('images/Corelation_Heatmap_2');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train shape: (3823, 30)\n",
      "X test shape: (1884, 30)\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(columns = 'Result')\n",
    "\n",
    "y = df['Result']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "print(f'X train shape: {X_train.shape}')\n",
    "print(f'X test shape: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"Raw Counts \n",
    "{df[\"Result\"].value_counts()}\\n\n",
    "Percentages \n",
    "{df[\"Result\"].value_counts(normalize=True)}\n",
    "\n",
    "\n",
    "We would get an accuracy score of {np.round(df[\"Result\"].value_counts(normalize=True)[1], 4)} with a baseline model, i.e. about 56.6% accuracy\n",
    "\n",
    "This is because about 55.79% of the results are wins\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"Train percent wins\n",
    "{y_train.value_counts(normalize=True)}\\n\"\"\")\n",
    "\n",
    "print(f\"\"\"Test percent wins: \n",
    "{y_test.value_counts(normalize=True)}\\n\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelWithCV():\n",
    "    '''Structure to save the model and more easily see its crossvalidation'''\n",
    "    \n",
    "    def __init__(self, model, model_name, X, y, cv_now=True):\n",
    "        self.model = model\n",
    "        self.name = model_name\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        # For CV results\n",
    "        self.cv_results = None\n",
    "        self.cv_mean = None\n",
    "        self.cv_median = None\n",
    "        self.cv_std = None\n",
    "        #\n",
    "        if cv_now:\n",
    "            self.cross_validate()\n",
    "        \n",
    "    def cross_validate(self, X=None, y=None, kfolds=10):\n",
    "        '''\n",
    "        Perform cross-validation and return results.\n",
    "        \n",
    "        Args: \n",
    "          X:\n",
    "            Optional; Training data to perform CV on. Otherwise use X from object\n",
    "          y:\n",
    "            Optional; Training data to perform CV on. Otherwise use y from object\n",
    "          kfolds:\n",
    "            Optional; Number of folds for CV (default is 10)  \n",
    "        '''\n",
    "        \n",
    "        cv_X = X if X else self.X\n",
    "        cv_y = y if y else self.y\n",
    "\n",
    "        self.cv_results = cross_val_score(self.model, cv_X, cv_y, cv=kfolds)\n",
    "        self.cv_mean = np.mean(self.cv_results)\n",
    "        self.cv_median = np.median(self.cv_results)\n",
    "        self.cv_std = np.std(self.cv_results)\n",
    "\n",
    "        \n",
    "    def print_cv_summary(self):\n",
    "        cv_summary = (\n",
    "        f'''CV Results for `{self.name}` model:\n",
    "            {self.cv_mean:.5f} ± {self.cv_std:.5f} accuracy\n",
    "        ''')\n",
    "        print(cv_summary)\n",
    "\n",
    "        \n",
    "    def plot_cv(self, ax):\n",
    "        '''\n",
    "        Plot the cross-validation values using the array of results and given \n",
    "        Axis for plotting.\n",
    "        '''\n",
    "        ax.set_title(f'CV Results for `{self.name}` Model')\n",
    "        # Thinner violinplot with higher bw\n",
    "        sns.violinplot(y=self.cv_results, ax=ax, bw=.4)\n",
    "        sns.swarmplot(\n",
    "                y=self.cv_results,\n",
    "                color='orange',\n",
    "                size=10,\n",
    "                alpha= 0.8,\n",
    "                ax=ax\n",
    "        )\n",
    "\n",
    "        return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dummy/Baseliner\n",
    "\n",
    "\n",
    "\n",
    "estimator = DummyRegressor(strategy='mean')\n",
    "\n",
    "# Create Dummy/Baseliner\n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "pipe = Pipeline(steps=[\n",
    "    ('estimator', DummyRegressor(strategy='mean'))\n",
    "])\n",
    "\n",
    "cv = ModelWithCV(pipe, 'estimator', X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots()\n",
    "\n",
    "cv.plot_cv(ax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.print_cv_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[\n",
    "    ('poly', PolynomialFeatures(degree=2)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA(n_components=4)),\n",
    "    ('estimator', LogisticRegression(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {}\n",
    "param_grid['estimator__C'] = [100, 10, 1.0, 0.1, 0.01]\n",
    "param_grid['estimator__solver'] = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "param_grid['estimator__penalty'] = ['l2']\n",
    "# param_grid['estimator__class_weight'] = ['balanced', None]\n",
    "# param_grid['estimator__n_jobs'] = [-1]\n",
    "# param_grid['estimator__l1_ratio'] = [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(estimator=pipe, \n",
    "                           param_grid=param_grid, \n",
    "                           cv=RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=42), \n",
    "                           return_train_score=True, \n",
    "                           scoring='accuracy', \n",
    "                           n_jobs=-1,\n",
    "                           verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 30 folds for each of 15 candidates, totalling 450 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=RepeatedStratifiedKFold(n_repeats=3, n_splits=10, random_state=42),\n",
       "             estimator=Pipeline(steps=[(&#x27;poly&#x27;, PolynomialFeatures()),\n",
       "                                       (&#x27;scaler&#x27;, StandardScaler()),\n",
       "                                       (&#x27;pca&#x27;, PCA(n_components=4)),\n",
       "                                       (&#x27;estimator&#x27;,\n",
       "                                        LogisticRegression(random_state=42))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;estimator__C&#x27;: [100, 10, 1.0, 0.1, 0.01],\n",
       "                         &#x27;estimator__penalty&#x27;: [&#x27;l2&#x27;],\n",
       "                         &#x27;estimator__solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;,\n",
       "                                               &#x27;liblinear&#x27;]},\n",
       "             return_train_score=True, scoring=&#x27;accuracy&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=RepeatedStratifiedKFold(n_repeats=3, n_splits=10, random_state=42),\n",
       "             estimator=Pipeline(steps=[(&#x27;poly&#x27;, PolynomialFeatures()),\n",
       "                                       (&#x27;scaler&#x27;, StandardScaler()),\n",
       "                                       (&#x27;pca&#x27;, PCA(n_components=4)),\n",
       "                                       (&#x27;estimator&#x27;,\n",
       "                                        LogisticRegression(random_state=42))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;estimator__C&#x27;: [100, 10, 1.0, 0.1, 0.01],\n",
       "                         &#x27;estimator__penalty&#x27;: [&#x27;l2&#x27;],\n",
       "                         &#x27;estimator__solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;,\n",
       "                                               &#x27;liblinear&#x27;]},\n",
       "             return_train_score=True, scoring=&#x27;accuracy&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;poly&#x27;, PolynomialFeatures()), (&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;pca&#x27;, PCA(n_components=4)),\n",
       "                (&#x27;estimator&#x27;, LogisticRegression(random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PolynomialFeatures</label><div class=\"sk-toggleable__content\"><pre>PolynomialFeatures()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA(n_components=4)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=RepeatedStratifiedKFold(n_repeats=3, n_splits=10, random_state=42),\n",
       "             estimator=Pipeline(steps=[('poly', PolynomialFeatures()),\n",
       "                                       ('scaler', StandardScaler()),\n",
       "                                       ('pca', PCA(n_components=4)),\n",
       "                                       ('estimator',\n",
       "                                        LogisticRegression(random_state=42))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'estimator__C': [100, 10, 1.0, 0.1, 0.01],\n",
       "                         'estimator__penalty': ['l2'],\n",
       "                         'estimator__solver': ['newton-cg', 'lbfgs',\n",
       "                                               'liblinear']},\n",
       "             return_train_score=True, scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Training Score: 64.44%\n",
      "\n",
      "Mean Test Score: 65.92%\n",
      "\n",
      "Accuracy Score: 65.92%\n",
      "\n",
      "Optimal Parameters: {'estimator__C': 0.1, 'estimator__penalty': 'l2', 'estimator__solver': 'liblinear'}\n",
      "\n",
      "Testing Accuracy: 64.22%\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.49      0.56       840\n",
      "           1       0.66      0.79      0.72      1044\n",
      "\n",
      "    accuracy                           0.66      1884\n",
      "   macro avg       0.66      0.64      0.64      1884\n",
      "weighted avg       0.66      0.66      0.65      1884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Mean training score\n",
    "grid_train_score = np.mean(grid_search.cv_results_['mean_train_score'])\n",
    "\n",
    "# Mean test score\n",
    "grid_test_score = grid_search.score(X_test, y_test)\n",
    "\n",
    "best_grid = grid_search.best_estimator_\n",
    "best_grid.fit(X_train, y_train)\n",
    "y_pred = best_grid.predict(X_test)\n",
    "\n",
    "print(f\"Mean Training Score: {grid_train_score:.2%}\\n\")\n",
    "print(f\"Mean Test Score: {grid_test_score:.2%}\\n\")\n",
    "\n",
    "print(f\"Accuracy Score: {accuracy_score(y_test, y_pred):.2%}\\n\")\n",
    "print(f\"Optimal Parameters: {grid_search.best_params_}\\n\")\n",
    "print(f\"Testing Accuracy: {grid_search.best_score_:.2%}\\n\")\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 30 folds for each of 10 candidates, totalling 300 fits\n",
      "Mean Training Score: 69.92%\n",
      "\n",
      "Mean Test Score: 65.02%\n",
      "\n",
      "Accuracy Score: 65.02%\n",
      "\n",
      "Optimal Parameters: {'estimator__alpha': 0.7}\n",
      "\n",
      "Testing Accuracy: 63.12%\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.52      0.57       840\n",
      "           1       0.66      0.76      0.71      1044\n",
      "\n",
      "    accuracy                           0.65      1884\n",
      "   macro avg       0.65      0.64      0.64      1884\n",
      "weighted avg       0.65      0.65      0.64      1884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline(steps=[\n",
    "    ('poly', PolynomialFeatures(degree=2)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('estimator', RidgeClassifier())\n",
    "])\n",
    "\n",
    "\n",
    "param_grid = {}\n",
    "param_grid['estimator__alpha'] = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "# param_grid['estimator__learning_rate'] = [0.001, 0.01, 0.1]\n",
    "# param_grid['estimator__subsample'] = [0.5, 0.7, 1.0]\n",
    "# param_grid['estimator__max_depth'] = [3, 7, 9]\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(estimator=pipe, \n",
    "                           param_grid=param_grid, \n",
    "                           cv=RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=42), \n",
    "                           return_train_score=True, \n",
    "                           scoring='accuracy',\n",
    "                           n_jobs=-1,\n",
    "                           verbose=2)\n",
    "\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Mean training score\n",
    "grid_train_score = np.mean(grid_search.cv_results_['mean_train_score'])\n",
    "\n",
    "# Mean test score\n",
    "grid_test_score = grid_search.score(X_test, y_test)\n",
    "\n",
    "best_grid = grid_search.best_estimator_\n",
    "best_grid.fit(X_train, y_train)\n",
    "y_pred = best_grid.predict(X_test)\n",
    "\n",
    "print(f\"Mean Training Score: {grid_train_score:.2%}\\n\")\n",
    "print(f\"Mean Test Score: {grid_test_score:.2%}\\n\")\n",
    "\n",
    "print(f\"Accuracy Score: {accuracy_score(y_test, y_pred):.2%}\\n\")\n",
    "print(f\"Optimal Parameters: {grid_search.best_params_}\\n\")\n",
    "print(f\"Testing Accuracy: {grid_search.best_score_:.2%}\\n\")\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest - Random Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('estimator', RandomForestClassifier(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {}\n",
    "param_grid['estimator__n_estimators'] = [int(x) for x in np.linspace(start=200, stop=2000, num=10)]\n",
    "param_grid['estimator__max_features'] = ['auto', 'sqrt', 'log2']\n",
    "param_grid['estimator__max_depth'] = [int(x) for x in np.linspace(10, 110, num=11)]\n",
    "param_grid['estimator__min_samples_split'] = [2, 5, 10]\n",
    "param_grid['estimator__min_samples_leaf'] = [1, 2, 4]\n",
    "#param_grid['estimator__bootstrap'] = [True, False]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = RandomizedSearchCV(estimator=pipe, \n",
    "                                 param_distributions=param_grid, \n",
    "                                 cv=10, \n",
    "                                 return_train_score=True, \n",
    "                                 scoring='accuracy', \n",
    "                                 n_iter=100, \n",
    "                                 random_state=42, \n",
    "                                 n_jobs=-1, \n",
    "                                 verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [41]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    869\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    871\u001b[0m     )\n\u001b[0;32m    873\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 875\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    879\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1753\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1751\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1752\u001b[0m     \u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1753\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1754\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1755\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[0;32m   1756\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1757\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:822\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    815\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    817\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    818\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    819\u001b[0m         )\n\u001b[0;32m    820\u001b[0m     )\n\u001b[1;32m--> 822\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    823\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    834\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    835\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    836\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    837\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    839\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    840\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    844\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:1056\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1053\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1055\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1056\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1057\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1058\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:935\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    933\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    934\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 935\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    936\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    937\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    539\u001b[0m \u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    540\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    541\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 542\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    543\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    544\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\concurrent\\futures\\_base.py:441\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[1;32m--> 441\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    444\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 312\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    313\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    314\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean training score\n",
    "grid_train_score = np.mean(grid_search.cv_results_['mean_train_score'])\n",
    "\n",
    "# Mean test score\n",
    "grid_test_score = grid_search.score(X_test, y_test)\n",
    "\n",
    "best_grid = grid_search.best_estimator_\n",
    "best_grid.fit(X_train, y_train)\n",
    "y_pred = best_grid.predict(X_test)\n",
    "\n",
    "print(f\"Mean Training Score: {grid_train_score:.2%}\\n\")\n",
    "print(f\"Mean Test Score: {grid_test_score:.2%}\\n\")\n",
    "\n",
    "print(f\"Accuracy Score: {accuracy_score(y_test, y_pred):.2%}\\n\")\n",
    "print(f\"Optimal Parameters: {grid_search.best_params_}\\n\")\n",
    "print(f\"Testing Accuracy: {grid_search.best_score_:.2%}\\n\")\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest - Grid Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[\n",
    "    ('estimator', RandomForestClassifier(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {}\n",
    "param_grid['estimator__n_estimators'] = [int(x) for x in np.linspace(start=200, stop=2000, num=10)]\n",
    "param_grid['estimator__max_features'] = ['auto', 'sqrt']\n",
    "param_grid['estimator__max_depth'] = [int(x) for x in np.linspace(10, 110, num=11)]\n",
    "param_grid['estimator__min_samples_split'] = [2, 5, 10]\n",
    "param_grid['estimator__min_samples_leaf'] = [1, 2, 4]\n",
    "# param_grid['estimator__bootstrap'] = [True, False]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(estimator=pipe, \n",
    "                           param_grid=param_grid, \n",
    "                           cv=RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=42), \n",
    "                           return_train_score=True, \n",
    "                           scoring='accuracy',\n",
    "                           n_jobs=-1,\n",
    "                           verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean training score\n",
    "grid_train_score = np.mean(grid_search.cv_results_['mean_train_score'])\n",
    "\n",
    "# Mean test score\n",
    "grid_test_score = grid_search.score(X_test, y_test)\n",
    "\n",
    "best_grid = grid_search.best_estimator_\n",
    "best_grid.fit(X_train, y_train)\n",
    "y_pred = best_grid.predict(X_test)\n",
    "\n",
    "print(f\"Mean Training Score: {grid_train_score:.2%}\\n\")\n",
    "print(f\"Mean Test Score: {grid_test_score:.2%}\\n\")\n",
    "\n",
    "print(f\"Accuracy Score: {accuracy_score(y_test, y_pred):.2%}\\n\")\n",
    "print(f\"Optimal Parameters: {grid_search.best_params_}\\n\")\n",
    "print(f\"Testing Accuracy: {grid_search.best_score_:.2%}\\n\")\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('estimator', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "\n",
    "param_grid = {}\n",
    "param_grid['estimator__n_estimators'] = [10, 100, 1000]\n",
    "param_grid['estimator__max_features'] = ['sqrt', 'log2']\n",
    "# param_grid['estimator__max_depth'] = [int(x) for x in np.linspace(10, 110, num=11)]\n",
    "# param_grid['estimator__min_samples_split'] = [2, 5, 10]\n",
    "# param_grid['estimator__min_samples_leaf'] = [1, 2, 4]\n",
    "# param_grid['estimator__bootstrap'] = [True, False]\n",
    "\n",
    "grid_search = GridSearchCV(estimator=pipe, \n",
    "                           param_grid=param_grid, \n",
    "                           cv=RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=42), \n",
    "                           return_train_score=True, \n",
    "                           scoring='accuracy',\n",
    "                           n_jobs=-1,\n",
    "                           verbose=2)\n",
    "\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Mean training score\n",
    "grid_train_score = np.mean(grid_search.cv_results_['mean_train_score'])\n",
    "\n",
    "# Mean test score\n",
    "grid_test_score = grid_search.score(X_test, y_test)\n",
    "\n",
    "best_grid = grid_search.best_estimator_\n",
    "best_grid.fit(X_train, y_train)\n",
    "y_pred = best_grid.predict(X_test)\n",
    "\n",
    "print(f\"Mean Training Score: {grid_train_score:.2%}\\n\")\n",
    "print(f\"Mean Test Score: {grid_test_score:.2%}\\n\")\n",
    "\n",
    "print(f\"Accuracy Score: {accuracy_score(y_test, y_pred):.2%}\\n\")\n",
    "print(f\"Optimal Parameters: {grid_search.best_params_}\\n\")\n",
    "print(f\"Testing Accuracy: {grid_search.best_score_:.2%}\\n\")\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = ImPipeline(steps=[\n",
    "    ('sm', SMOTE(random_state=42)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('estimator', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "\n",
    "param_grid = {}\n",
    "param_grid['estimator__n_estimators'] = [10, 100, 1000]\n",
    "param_grid['estimator__max_features'] = ['sqrt', 'log2']\n",
    "param_grid['estimator__k_neighbors'] = [3, 5, 7]\n",
    "\n",
    "# param_grid['estimator__max_depth'] = [int(x) for x in np.linspace(10, 110, num=11)]\n",
    "# param_grid['estimator__min_samples_split'] = [2, 5, 10]\n",
    "# param_grid['estimator__min_samples_leaf'] = [1, 2, 4]\n",
    "\n",
    "grid_search = GridSearchCV(estimator=pipe, \n",
    "                           param_grid=param_grid, \n",
    "                           cv=RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=42), \n",
    "                           return_train_score=True, \n",
    "                           scoring='accuracy',\n",
    "                           n_jobs=-1,\n",
    "                           verbose=2)\n",
    "\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Mean training score\n",
    "grid_train_score = np.mean(grid_search.cv_results_['mean_train_score'])\n",
    "\n",
    "# Mean test score\n",
    "grid_test_score = grid_search.score(X_test, y_test)\n",
    "\n",
    "best_grid = grid_search.best_estimator_\n",
    "best_grid.fit(X_train, y_train)\n",
    "y_pred = best_grid.predict(X_test)\n",
    "\n",
    "print(f\"Mean Training Score: {grid_train_score:.2%}\\n\")\n",
    "print(f\"Mean Test Score: {grid_test_score:.2%}\\n\")\n",
    "\n",
    "print(f\"Accuracy Score: {accuracy_score(y_test, y_pred):.2%}\\n\")\n",
    "print(f\"Optimal Parameters: {grid_search.best_params_}\\n\")\n",
    "print(f\"Testing Accuracy: {grid_search.best_score_:.2%}\\n\")\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('estimator', GaussianNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {}\n",
    "param_grid['estimator__var_smoothing'] = np.logspace(0,-11, num=100)\n",
    "#param_grid['estimator__var_smoothing'] = [1e-11, 1e-10, 1e-9]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = RandomizedSearchCV(estimator=pipe, \n",
    "                                 param_distributions=param_grid, \n",
    "                                 cv=RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=42), \n",
    "                                 return_train_score=True, \n",
    "                                 scoring='accuracy', \n",
    "                                 random_state=42,\n",
    "                                 n_jobs = -1,\n",
    "                                 verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Mean training score\n",
    "grid_train_score = np.mean(grid_search.cv_results_['mean_train_score'])\n",
    "\n",
    "# Mean test score\n",
    "grid_test_score = grid_search.score(X_test, y_test)\n",
    "\n",
    "best_grid = grid_search.best_estimator_\n",
    "best_grid.fit(X_train, y_train)\n",
    "y_pred = best_grid.predict(X_test)\n",
    "\n",
    "print(f\"Mean Training Score: {grid_train_score:.2%}\\n\")\n",
    "print(f\"Mean Test Score: {grid_test_score:.2%}\\n\")\n",
    "\n",
    "print(f\"Accuracy Score: {accuracy_score(y_test, y_pred):.2%}\\n\")\n",
    "print(f\"Optimal Parameters: {grid_search.best_params_}\\n\")\n",
    "print(f\"Testing Accuracy: {grid_search.best_score_:.2%}\\n\")\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('estimator', GaussianNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {}\n",
    "param_grid['estimator__var_smoothing'] = np.logspace(0,-11, num=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(estimator=pipe, \n",
    "                           param_grid=param_grid, \n",
    "                           cv=RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=42), \n",
    "                           return_train_score=True, \n",
    "                           scoring='accuracy', \n",
    "                           random_state=42,\n",
    "                           n_jobs=-1,\n",
    "                           verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean training score\n",
    "grid_train_score = np.mean(grid_search.cv_results_['mean_train_score'])\n",
    "\n",
    "# Mean test score\n",
    "grid_test_score = grid_search.score(X_test, y_test)\n",
    "\n",
    "best_grid = grid_search.best_estimator_\n",
    "best_grid.fit(X_train, y_train)\n",
    "y_pred = best_grid.predict(X_test)\n",
    "\n",
    "print(f\"Mean Training Score: {grid_train_score:.2%}\\n\")\n",
    "print(f\"Mean Test Score: {grid_test_score:.2%}\\n\")\n",
    "\n",
    "print(f\"Accuracy Score: {accuracy_score(y_test, y_pred):.2%}\\n\")\n",
    "print(f\"Optimal Parameters: {grid_search.best_params_}\\n\")\n",
    "print(f\"Testing Accuracy: {grid_search.best_score_:.2%}\\n\")\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('estimator', KNeighborsClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {}\n",
    "param_grid['estimator__n_neighbors'] = range(1, 21, 2)\n",
    "param_grid['estimator__p'] = [1, 2]\n",
    "param_grid['estimator__weights'] = ['uniform', 'distance']\n",
    "param_grid['estimator__metric'] = ['euclidean', 'manhattan', 'minkowski']\n",
    "# param_grid['estimator__leaf_size'] = (20, 40, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(estimator=pipe, \n",
    "                           param_grid=param_grid, \n",
    "                           cv=RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=42), \n",
    "                           return_train_score=True, \n",
    "                           scoring='accuracy', \n",
    "                           random_state=42,\n",
    "                           n_jobs = -1,\n",
    "                           verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean training score\n",
    "grid_train_score = np.mean(grid_search.cv_results_['mean_train_score'])\n",
    "\n",
    "# Mean test score\n",
    "grid_test_score = grid_search.score(X_test, y_test)\n",
    "\n",
    "best_grid = grid_search.best_estimator_\n",
    "best_grid.fit(X_train, y_train)\n",
    "y_pred = best_grid.predict(X_test)\n",
    "\n",
    "print(f\"Mean Training Score: {grid_train_score:.2%}\\n\")\n",
    "print(f\"Mean Test Score: {grid_test_score:.2%}\\n\")\n",
    "\n",
    "print(f\"Accuracy Score: {accuracy_score(y_test, y_pred):.2%}\\n\")\n",
    "print(f\"Optimal Parameters: {grid_search.best_params_}\\n\")\n",
    "print(f\"Testing Accuracy: {grid_search.best_score_:.2%}\\n\")\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 30 folds for each of 81 candidates, totalling 2430 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 24>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# param_grid['estimator__min_samples_leaf'] = [1, 2, 4]\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# param_grid['estimator__bootstrap'] = [True, False]\u001b[39;00m\n\u001b[0;32m     15\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mpipe, \n\u001b[0;32m     16\u001b[0m                            param_grid\u001b[38;5;241m=\u001b[39mparam_grid, \n\u001b[0;32m     17\u001b[0m                            cv\u001b[38;5;241m=\u001b[39mRepeatedStratifiedKFold(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, n_repeats\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m), \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     20\u001b[0m                            n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     21\u001b[0m                            verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m---> 24\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Mean training score\u001b[39;00m\n\u001b[0;32m     28\u001b[0m grid_train_score \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(grid_search\u001b[38;5;241m.\u001b[39mcv_results_[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_train_score\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    869\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    871\u001b[0m     )\n\u001b[0;32m    873\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 875\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    879\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1379\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1378\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1379\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:822\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    815\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    817\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    818\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    819\u001b[0m         )\n\u001b[0;32m    820\u001b[0m     )\n\u001b[1;32m--> 822\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    823\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    834\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    835\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    836\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    837\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    839\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    840\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    844\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:1056\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1053\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1055\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1056\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1057\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1058\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:935\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    933\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    934\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 935\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    936\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    937\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    539\u001b[0m \u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    540\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    541\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 542\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    543\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    544\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\concurrent\\futures\\_base.py:441\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[1;32m--> 441\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    444\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 312\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    313\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    314\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pipe = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('estimator', GradientBoostingClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "\n",
    "param_grid = {}\n",
    "param_grid['estimator__n_estimators'] = [10, 100, 1000]\n",
    "param_grid['estimator__learning_rate'] = [0.001, 0.01, 0.1]\n",
    "param_grid['estimator__subsample'] = [0.5, 0.7, 1.0]\n",
    "param_grid['estimator__max_depth'] = [3, 7, 9]\n",
    "# param_grid['estimator__min_samples_leaf'] = [1, 2, 4]\n",
    "# param_grid['estimator__bootstrap'] = [True, False]\n",
    "\n",
    "grid_search = GridSearchCV(estimator=pipe, \n",
    "                           param_grid=param_grid, \n",
    "                           cv=RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=42), \n",
    "                           return_train_score=True, \n",
    "                           scoring='accuracy',\n",
    "                           n_jobs=-1,\n",
    "                           verbose=2)\n",
    "\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Mean training score\n",
    "grid_train_score = np.mean(grid_search.cv_results_['mean_train_score'])\n",
    "\n",
    "# Mean test score\n",
    "grid_test_score = grid_search.score(X_test, y_test)\n",
    "\n",
    "best_grid = grid_search.best_estimator_\n",
    "best_grid.fit(X_train, y_train)\n",
    "y_pred = best_grid.predict(X_test)\n",
    "\n",
    "print(f\"Mean Training Score: {grid_train_score:.2%}\\n\")\n",
    "print(f\"Mean Test Score: {grid_test_score:.2%}\\n\")\n",
    "\n",
    "print(f\"Accuracy Score: {accuracy_score(y_test, y_pred):.2%}\\n\")\n",
    "print(f\"Optimal Parameters: {grid_search.best_params_}\\n\")\n",
    "print(f\"Testing Accuracy: {grid_search.best_score_:.2%}\\n\")\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('estimator', SVC(random_state=42))\n",
    "])\n",
    "\n",
    "kernel = ['poly', 'rbf', 'sigmoid']\n",
    "C = [50, 10, 1.0, 0.1, 0.01]\n",
    "gamma = ['scale']\n",
    "\n",
    "\n",
    "param_grid = {}\n",
    "param_grid['estimator__kernel'] = ['poly', 'rbf', 'sigmoid']\n",
    "param_grid['estimator__C'] = [50, 10, 1.0, 0.1, 0.01]\n",
    "param_grid['estimator__gamma'] = ['scale']\n",
    "\n",
    "grid_search = RandomizedSearchCV(estimator=pipe, \n",
    "                                 param_distributions=param_grid, \n",
    "                                 cv=RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=42), \n",
    "                                 return_train_score=True, \n",
    "                                 scoring='accuracy', \n",
    "                                 n_iter=100, \n",
    "                                 random_state=42, \n",
    "                                 n_jobs=-1, \n",
    "                                 verbose=2)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=pipe, \n",
    "                           param_grid=param_grid, \n",
    "                           cv=RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=42), \n",
    "                           return_train_score=True, \n",
    "                           scoring='accuracy', \n",
    "                           random_state=42,\n",
    "                           n_jobs = -1,\n",
    "                           verbose=2)\n",
    "\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Mean training score\n",
    "grid_train_score = np.mean(grid_search.cv_results_['mean_train_score'])\n",
    "\n",
    "# Mean test score\n",
    "grid_test_score = grid_search.score(X_test, y_test)\n",
    "\n",
    "best_grid = grid_search.best_estimator_\n",
    "best_grid.fit(X_train, y_train)\n",
    "y_pred = best_grid.predict(X_test)\n",
    "\n",
    "print(f\"Mean Training Score: {grid_train_score:.2%}\\n\")\n",
    "print(f\"Mean Test Score: {grid_test_score:.2%}\\n\")\n",
    "\n",
    "print(f\"Accuracy Score: {accuracy_score(y_test, y_pred):.2%}\\n\")\n",
    "print(f\"Optimal Parameters: {grid_search.best_params_}\\n\")\n",
    "print(f\"Testing Accuracy: {grid_search.best_score_:.2%}\\n\")\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[\n",
    "    ('estimator', xgboost.XGBRegressor(random_state=42, objective='reg:squarederror'))\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {}\n",
    "param_grid['estimator__min_child_weight'] = [1, 5, 10],\n",
    "param_grid['estimator__gamma'] = [0.5, 1, 1.5, 2, 5],\n",
    "param_grid['estimator__subsample'] = [0.6, 0.8, 1.0],\n",
    "param_grid['estimator__colsample_bytree'] = [0.6, 0.8, 1.0],\n",
    "param_grid['estimator__max_depth'] = [3, 4, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(estimator=pipe, \n",
    "                           param_grid=param_grid, \n",
    "                           cv=10, \n",
    "                           return_train_score=True, \n",
    "                           scoring='accuracy',\n",
    "                           n_jobs = -1,\n",
    "                           verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean training score\n",
    "grid_train_score = np.mean(grid_search.cv_results_['mean_train_score'])\n",
    "\n",
    "# Mean test score\n",
    "grid_test_score = grid_search.score(X_test, y_test)\n",
    "\n",
    "best_grid = grid_search.best_estimator_\n",
    "best_grid.fit(X_train, y_train)\n",
    "y_pred = best_grid.predict(X_test)\n",
    "\n",
    "print(f\"Mean Training Score: {grid_train_score:.2%}\\n\")\n",
    "print(f\"Mean Test Score: {grid_test_score:.2%}\\n\")\n",
    "\n",
    "print(f\"Accuracy Score: {accuracy_score(y_test, y_pred):.2%}\\n\")\n",
    "print(f\"Optimal Parameters: {grid_search.best_params_}\\n\")\n",
    "print(f\"Testing Accuracy: {grid_search.best_score_:.2%}\\n\")\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a confusion matrix on the test data\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(final_model, X_test, y_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import model_selection\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "#script to test the effectivenes of each model, uses default parameters\n",
    "#test six different classification models \n",
    "def run_exps(X_train, y_train, X_test, y_test) :\n",
    "    '''\n",
    "    Lightweight script to test many models and find winners\n",
    "    :param X_train: training split\n",
    "    :param y_train: training target vector\n",
    "    :param X_test: test split\n",
    "    :param y_test: test target vector\n",
    "    :return: DataFrame of predictions\n",
    "    '''\n",
    "    \n",
    "    dfs = []\n",
    "    \n",
    "    models = [\n",
    "          ('LogReg', LogisticRegression()), \n",
    "          ('RF', RandomForestClassifier()),\n",
    "          ('KNN', KNeighborsClassifier()),\n",
    "          ('SVM', SVC()), \n",
    "          ('GNB', GaussianNB()),\n",
    "          ('XGB', XGBClassifier())\n",
    "        ]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    names = []\n",
    "    \n",
    "    scoring = ['accuracy', 'precision_weighted', 'recall_weighted', 'f1_weighted', 'roc_auc']\n",
    "    \n",
    "    target_names = ['win', 'loss']\n",
    "    \n",
    "    for name, model in models:\n",
    "        \n",
    "        kfold = model_selection.KFold(n_splits=5, shuffle=True, random_state=90210)\n",
    "        cv_results = model_selection.cross_validate(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "        clf = model.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        \n",
    "        print(name)\n",
    "        print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "        \n",
    "        results.append(cv_results)\n",
    "        names.append(name)\n",
    "        \n",
    "        this_df = pd.DataFrame(cv_results)\n",
    "        this_df['model'] = name\n",
    "        dfs.append(this_df)\n",
    "        \n",
    "    final = pd.concat(dfs, ignore_index=True)\n",
    "    \n",
    "    return final\n",
    "final = run_exps(X_train, y_train, X_test, y_test)\n",
    "final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstraps = []\n",
    "for model in list(set(final.model.values)):\n",
    "    model_df = final.loc[final.model == model]\n",
    "    bootstrap = model_df.sample(n=30, replace=True)\n",
    "    bootstraps.append(bootstrap)\n",
    "        \n",
    "bootstrap_df = pd.concat(bootstraps, ignore_index=True)\n",
    "results_long = pd.melt(bootstrap_df,id_vars=['model'],var_name='metrics', value_name='values')\n",
    "time_metrics = ['fit_time','score_time'] # fit time metrics\n",
    "## PERFORMANCE METRICS\n",
    "results_long_nofit = results_long.loc[~results_long['metrics'].isin(time_metrics)] # get df without fit data\n",
    "results_long_nofit = results_long_nofit.sort_values(by='values')\n",
    "## TIME METRICS\n",
    "results_long_fit = results_long.loc[results_long['metrics'].isin(time_metrics)] # df with fit data\n",
    "results_long_fit = results_long_fit.sort_values(by='values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(20, 12))\n",
    "sns.set(font_scale=2.5)\n",
    "g = sns.boxplot(x=\"model\", y=\"values\", hue=\"metrics\", data=results_long_nofit, palette=\"Set3\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.title('Comparison of Model by Classification Metric')\n",
    "plt.savefig('./benchmark_models_performance.png',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 12))\n",
    "sns.set(font_scale=2.5)\n",
    "g = sns.boxplot(x=\"model\", y=\"values\", hue=\"metrics\", data=results_long_fit, palette=\"Set3\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.title('Comparison of Model by Fit and Score Time')\n",
    "plt.savefig('./benchmark_models_time.png',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = list(set(results_long_nofit.metrics.values))\n",
    "bootstrap_df.groupby(['model'])[metrics].agg([np.std, np.mean])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Selected Model\n",
    "- grid search for parameters \n",
    "- Gaussian NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian NB only has one parameter 'var_smoothing'\n",
    "# Portion of the largest variance of all features that is added to variances for calculation stability.\n",
    "# Number of different combinations of parameters \n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "nb_classifier = GaussianNB()\n",
    "\n",
    "target_names = ['Win', 'Loss']\n",
    "\n",
    "params_NB = {'var_smoothing': np.logspace(0,-9, num=100)}\n",
    "kfold = model_selection.KFold(n_splits=5, shuffle=True, random_state=90210)\n",
    "\n",
    "gs_NB = GridSearchCV(estimator=nb_classifier, \n",
    "                 param_grid=params_NB, \n",
    "                 cv=kfold,   \n",
    "                 verbose=1, \n",
    "                 scoring='accuracy', n_jobs=-1) \n",
    "\n",
    "gs_NB.fit(X_train, y_train)\n",
    "\n",
    "best_gs_grid = gs_NB.best_estimator_\n",
    "best_gs_grid.fit(X_train, y_train)\n",
    "y_pred_best_gs = best_gs_grid.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_best_gs, target_names=target_names))\n",
    "gs_NB.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusionMatrix = confusion_matrix(y_test, y_pred_best_gs)\n",
    "print(confusionMatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusionMatrix = confusion_matrix(y_test, y_pred_best_gs)  \n",
    "\n",
    "    # Code below prints model accuracy information\n",
    "print('Coefficient Information:')\n",
    "\n",
    "for i in range(len(featureColumns)):  \n",
    "\n",
    "    logregCoefficients = logreg.coef_\n",
    "\n",
    "    currentFeature = featureColumns[i]\n",
    "    currentCoefficient = logregCoefficients[0][i]\n",
    "\n",
    "    print(currentFeature + ': ' + str(currentCoefficient))\n",
    "\n",
    "print('----------------------------------')\n",
    "\n",
    "print(\"Accuracy:\", metrics.accuracy_score(Y_test, Y_pred))\n",
    "print(\"Precision:\", metrics.precision_score(Y_test, Y_pred))\n",
    "print(\"Recall:\", metrics.recall_score(Y_test, Y_pred))\n",
    "\n",
    "print('----------------------------------')\n",
    "\n",
    "print('Confusion Matrix:')\n",
    "print(confusionMatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Saves the model in folder to be used in future\n",
    "# filename should be end in '.pkl'\n",
    "def save_model(model, filename):\n",
    "\n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump(model, file)\n",
    "save_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
